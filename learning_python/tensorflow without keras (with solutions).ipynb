{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a custom regression model without Keras\n",
    "\n",
    "Suggested reading:\n",
    "* https://www.tensorflow.org/tutorials/customization/autodiff\n",
    "* https://www.tensorflow.org/tutorials/customization/custom_training\n",
    "\n",
    "\n",
    "## Our Model\n",
    "Denote by $X$ the maximal daily temperature (in Celsius) at a given day and by $Y$ a number of ice-creams sold on that day. We want to model dependency of $Y$ on $X$. Consider the model \n",
    "$$ Y \\sim \\mathrm{Poisson}\\big[rate=\\mathrm{softplus(a X + b)}\\big]$$\n",
    "where $a, b\\in \\mathbb R$ are unknown constants. \n",
    "\n",
    "## Generate some artificial data\n",
    "We assume $a = 0.1$; $b=4$ are the real values of the constants we want to find and we have 1000 observations. Thus our data consist of vectors `X`, `Y` of length 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few elements of X: [ 15.110626    4.2292204  -4.1969495 -10.360373  -12.3682785]\n",
      "First few elements of Y: [4. 4. 7. 3. 2.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "X = tfd.Normal(0, 10).sample(1000)\n",
    "print(\"First few elements of X:\", X[:5].numpy())\n",
    "\n",
    "rate = tf.nn.softplus(0.1 * X + 4)\n",
    "\n",
    "Y = tfd.Poisson(rate).sample()\n",
    "print(\"First few elements of Y:\", Y[:5].numpy())\n",
    "\n",
    "# plotting\n",
    "plt.figure(figsize=[9, 3])\n",
    "ax = plt.gca()\n",
    "ax.scatter(X, Y)\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "We will find the parameters by maximizing the likelihood.\n",
    "\n",
    "### Exercise 1\n",
    "Write a function calculating the `loss` that is the negative log-likelihood of the parameters for given data. Make sure you use only `tensorflow` and `tensorflow-probability`, not `numpy` or `scipy`.\n",
    "\n",
    "Hint: I would use the following functions: `tf.nn.softplus`, `tf.reduce_sum` and `log_prob` method of `tfd.Poisson`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(a, b, X, Y):\n",
    "    \"\"\" Return the negative log-likelihood of the params `a, b`. \n",
    "    \n",
    "    Args:\n",
    "        a, b: scalars; parameters of our model\n",
    "        X: vector of measured daily temperatures\n",
    "        Y: observed numbers of sold ice-creams on the corresponding days\n",
    "        \n",
    "    Returns:\n",
    "        scalar `- log( P[Y | a, b, X] )`\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    rate = tf.nn.softplus(a * X + b)\n",
    "    distr = tfd.Poisson(rate)\n",
    "    return - tf.reduce_sum(distr.log_prob(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a little test\n",
    "l = get_loss(a=1., b=2., X=tf.constant([-10., 0., 10.]), Y=[1, 2, 3])\n",
    "assert np.allclose(l, 15.648288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current estimate of each parameter will be stored in a `tf.Variable`\n",
    "# We initialize these variables with some arbitrary numbers.\n",
    "\n",
    "a = tf.Variable(1, name=\"a\", dtype=K.floatx())\n",
    "b = tf.Variable(0, name=\"b\", dtype=K.floatx())\n",
    "weights = [a, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the `optimizer` to be used for minimization of the loss\n",
    "optimizer = tf.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "In the following cell complete the inside of the optimization loop -- evaluate the current `loss` and use the `tf.GradientTape` to calculate the gradient with respect to the weights. Assign the gra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2078.1162 0.092318445 3.9703152\n"
     ]
    }
   ],
   "source": [
    "for step in range(10000):\n",
    "    # calculate current loss and use `tf.GradientTape` to calculate loss gradients with respect to the `weights`\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = get_loss(a, b, X, Y)\n",
    "\n",
    "    grads = tape.gradient(loss, weights)\n",
    "    \n",
    "    # using the `optimizer` we can use the calculated gradients to update the values of `weights`\n",
    "    optimizer.apply_gradients(zip(grads, weights))\n",
    "\n",
    "print(loss.numpy(), a.numpy(), b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed things up using `tf.function`\n",
    "Try so read the \"basics\" part of the following tutorial:\n",
    "https://www.tensorflow.org/tutorials/customization/performance\n",
    "\n",
    "Using `tf.function` decorator often speeds the calculations a lot! (And sometimes not.) Unfortunately not all the code that works well in the eager-mode (un-decorated) compiles well to graph-mode (decorated). If you will use it, be prapared for some fight. \n",
    "\n",
    "### Exercise 3\n",
    "Copy your `quadratic_fun` from the previous exercise. \n",
    "Use the `%%timeit` magic to measure the time we need to run it.\n",
    "Then use `tf.function` decorator and measure the time again. Here the difference in speed will not be large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_fun(a, b, c, x):\n",
    "    # Your code comes here\n",
    "    return tf.reduce_sum((tf.linalg.matvec(a, x) + b) * x, axis = [-1]) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402 µs ± 23.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "quadratic_fun(a=tf.zeros([n, n]), b=tf.zeros(n), c=0, x=tf.ones([1000, n]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tf.function(quadratic_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473 µs ± 8.95 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit f(a=tf.zeros([n, n]), b=tf.zeros(n), c=0, x=tf.ones([1000, n]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "copy the content of the optimization for-loop in the first exercise into one function without arguments \n",
    "```python\n",
    "def train_step():\n",
    "    # your code here\n",
    "```\n",
    "Then use `%timeit` magic to see the difference in speed of the decorated and un-decorated versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = get_loss(a, b, X, Y)\n",
    "\n",
    "    grads = tape.gradient(loss, weights)\n",
    "    \n",
    "    # using the `optimizer` we can use the calculated gradients to update the values of `weights`\n",
    "    optimizer.apply_gradients(zip(grads, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.09 ms ± 90.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = tf.function(train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.4 ns ± 4.14 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Remark\n",
    "Feel free to skip this.\n",
    "\n",
    "Decorating by `tf.function` does not do much. The compilation to the computation-graph happens only when the decorated function is called for the first time. The `tensorflow` then knows what are the shapes of the incomming tensors and creates a graph whose inputs have the corresponding shapes. This compilation is quite time-consuming, but the good thing is that happens only once. \n",
    "\n",
    "Unless you call the decorated function with arguments of different shapes! In that case it happens again. Fortunately you can specify the input-shapes in advance, including not-completely defined shapes. The tensorflow then creates one graph whose imputs have partially defined shapes and uses this graph for all subsequent evaluations of the decorated function. To do this, you must specify the `input_signature` parameter of the `tf.function`.\n",
    "\n",
    "As an example consider the case when we want to use our `quadratic_fun` only in 5-dimensional space and with 1-dimensional batches of vectors `x`. However the size of the batch is unknown in advance and can change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "input_signature=[tf.TensorSpec([n, n], K.floatx()), \n",
    "                 tf.TensorSpec([n], K.floatx()), \n",
    "                 tf.TensorSpec([], K.floatx()), \n",
    "                 tf.TensorSpec([None, n], K.floatx())  # `x` has unknown batch-size\n",
    "                ]\n",
    "\n",
    "@tf.function(input_signature=input_signature)\n",
    "def quadratic_fun__decorated(a, b, c, x):\n",
    "    # Using Honza's calculation:\n",
    "    return tf.reduce_sum((tf.linalg.matvec(a, x) + b) * x, axis = [-1]) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadratic_fun__decorated(tf.zeros([5, 5]), tf.zeros([5]), 0., tf.zeros([2, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadratic_fun__decorated(tf.zeros([5, 5]), tf.zeros([5]), 0., tf.zeros([3, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Python inputs incompatible with input_signature:\n  inputs: (\n    tf.Tensor(\n[[0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]], shape=(6, 6), dtype=float32),\n    tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32),\n    0.0,\n    tf.Tensor(\n[[0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]], shape=(3, 6), dtype=float32))\n  input_signature: (\n    TensorSpec(shape=(5, 5), dtype=tf.float32, name=None),\n    TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n    TensorSpec(shape=(), dtype=tf.float32, name=None),\n    TensorSpec(shape=(None, 5), dtype=tf.float32, name=None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f9bd8c505dfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# The following evaluation now fails since the inputs are not consistent with the `input_signature`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mquadratic_fun__decorated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\git\\bordel\\python_bordel_01\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git\\bordel\\python_bordel_01\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32md:\\git\\bordel\\python_bordel_01\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2360\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2362\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2363\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git\\bordel\\python_bordel_01\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m       args, kwargs = self._function_spec.canonicalize_function_inputs(\n\u001b[1;32m-> 2661\u001b[1;33m           *args, **kwargs)\n\u001b[0m\u001b[0;32m   2662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m     \u001b[0mcache_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git\\bordel\\python_bordel_01\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcanonicalize_function_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2183\u001b[0m           \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2184\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_signature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2185\u001b[1;33m           self._flat_input_signature)\n\u001b[0m\u001b[0;32m   2186\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git\\bordel\\python_bordel_01\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_convert_inputs_to_signature\u001b[1;34m(inputs, input_signature, flat_input_signature)\u001b[0m\n\u001b[0;32m   2250\u001b[0m       flatten_inputs)):\n\u001b[0;32m   2251\u001b[0m     raise ValueError(\"Python inputs incompatible with input_signature:\\n%s\" %\n\u001b[1;32m-> 2252\u001b[1;33m                      format_error_message(inputs, input_signature))\n\u001b[0m\u001b[0;32m   2253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2254\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mneed_packing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Python inputs incompatible with input_signature:\n  inputs: (\n    tf.Tensor(\n[[0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]], shape=(6, 6), dtype=float32),\n    tf.Tensor([0. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32),\n    0.0,\n    tf.Tensor(\n[[0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0.]], shape=(3, 6), dtype=float32))\n  input_signature: (\n    TensorSpec(shape=(5, 5), dtype=tf.float32, name=None),\n    TensorSpec(shape=(5,), dtype=tf.float32, name=None),\n    TensorSpec(shape=(), dtype=tf.float32, name=None),\n    TensorSpec(shape=(None, 5), dtype=tf.float32, name=None))"
     ]
    }
   ],
   "source": [
    "# The following evaluation now fails since the inputs are not consistent with the `input_signature`\n",
    "quadratic_fun__decorated(tf.zeros([6, 6]), tf.zeros([6]), 0., tf.zeros([3, 6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional reading - Datasets\n",
    "Read first part \"Basic Mechanics\" of this tutorial:\n",
    "https://www.tensorflow.org/guide/data#basic_mechanics\n",
    "\n",
    "### Optional Exercise 5\n",
    "Let's return to our ice-cream regression.\n",
    "Imagine that we can't evaluate our model (because it is too complicated and we have too much data) at once and we want to use the stochastic-descent on mini-batches created from the data. \n",
    "* Use `tf.data.Dataset.from_tensor_slices` to create a dataset from our data tensors `X`, `Y`\n",
    "* use `shuffle` and `batch` methods of the dataset to create a shuffled and batched dataset, say with batches of length 100.\n",
    "* Write a new training loop where in each epoch you iterate through all the batches in the batched data-set and apply the gradient descent (or a fancier optimizer optimizer like adam) to each batch separately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
