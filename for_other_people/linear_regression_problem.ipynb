{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.keras import layers as kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplest example - gaussian distribution\n",
    "distr_layer = tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc = t[... , 0], scale = 1))\n",
    "# zde se tfd.Normal nahradi tfd.NegativeBinomial, u ktereho chci ale odhadovat 2 parametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplest model - linear regression\n",
    "model = tf.keras.models.Sequential([\n",
    "    kl.Dense(units = 1, use_bias = False),\n",
    "    distr_layer\n",
    "])\n",
    "negloglik = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "model.compile(optimizer='adam', loss=negloglik)\n",
    "#model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000 # sample size\n",
    "coefs = np.array([[1, 2, 3]]).T # true linear regression (= dense layer's) coeffs, 3 regressors\n",
    "tf.random.set_seed(1)\n",
    "X = tfd.Normal(1, 1).sample(sample_shape = [N, 3]) # random regression matrix (inputs)\n",
    "# zde coeffs zmenime na 3 x 2 matici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_distr_params = X @ coefs # means of the respective normal distributions (Y)\n",
    "true_distr = distr_layer(true_distr_params)\n",
    "tf.random.set_seed(1)\n",
    "Y = true_distr.sample() # sample some targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(negloglik(Y, true_distr)) # sample loss with true model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(negloglik(Y, model(X))) # sample loss with randomly initialized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights # initial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model (surprisingly does not work!!!)  \n",
    "# it seems there is some quadratic prior on model parameters and we are not able to turn it off\n",
    "model.fit(x = X, y = Y, epochs = 100, batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights # not a very good output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights[0] * model.weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss for \"manual\" optimization\n",
    "def get_loss():\n",
    "    return tf.reduce_mean(negloglik(Y, model(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam() # the same optimizer as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually apply optimizer's gradient step to the model weights\n",
    "@tf.function\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = get_loss()\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train as long as you wish :-)\n",
    "for i in range(1000):\n",
    "    loss = train_step()\n",
    "    if i % 100 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable_weights # correct weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
