{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.keras import layers as kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr_layer = tfp.layers.DistributionLambda(lambda t: tfd.NegativeBinomial(\n",
    "        total_count = tf.math.softplus(t[... , 0]), logits = t[..., 1]    \n",
    "       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    \n",
    "    kl.Dense(2),\n",
    "       \n",
    "    distr_layer\n",
    "    \n",
    "])\n",
    "negloglik = lambda x, rv_x: tf.reduce_mean(-rv_x.log_prob(x))\n",
    "model.compile(optimizer='adam', loss=negloglik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.NegativeBinomial 'sequential/distribution_lambda/NegativeBinomial/' batch_shape=[2] event_shape=[] dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.constant([[1,2,3],[-1,0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'sequential/dense/kernel:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[ 0.14176834, -0.6824337 ],\n",
       "        [-0.5987934 ,  0.39817536],\n",
       "        [ 0.18142378,  0.7412889 ]], dtype=float32)>,\n",
       " <tf.Variable 'sequential/dense/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=82, shape=(), dtype=float32, numpy=0.36463216>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = tfd.Normal(0, 1)\n",
    "d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "coefs = np.array([[1, 2, 3],[3, 2, 1]]).T\n",
    "bias = np.array([3, 0])\n",
    "X = tfd.Normal(1, 1).sample(sample_shape = [N, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=104, shape=(10000, 3), dtype=float32, numpy=\n",
       "array([[ 0.5539832 , -0.8368081 ,  2.6849008 ],\n",
       "       [ 0.87797767, -0.7828914 ,  0.65795726],\n",
       "       [ 1.301696  ,  1.3853161 ,  2.053258  ],\n",
       "       ...,\n",
       "       [ 3.0525506 , -0.31443965,  1.8236    ],\n",
       "       [ 0.5653211 ,  0.12393051,  1.8508487 ],\n",
       "       [ 1.1416686 ,  2.1904838 ,  2.3637786 ]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_neg_bin_params = X @ coefs + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=108, shape=(10000, 2), dtype=float32, numpy=\n",
       "array([[ 9.935069 ,  2.6732342],\n",
       "       [ 4.2860665,  1.7261076],\n",
       "       [13.232101 ,  8.728978 ],\n",
       "       ...,\n",
       "       [10.894471 , 10.352372 ],\n",
       "       [ 9.365728 ,  3.794673 ],\n",
       "       [15.613972 , 10.169752 ]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_neg_bin_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_distr = distr_layer(true_neg_bin_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = true_distr.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "917772.75\n"
     ]
    }
   ],
   "source": [
    "# old_weights = model.get_weights()\n",
    "# model.set_weights([coefs, bias])\n",
    "# model_distr = model(X)\n",
    "# print(model.evaluate(X, Y, batch_size=100000, verbose=0))\n",
    "# model.set_weights(old_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights([coefs, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.614815"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(negloglik(Y, true_distr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2227965.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(negloglik(Y, model(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5707.3525390625\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X, Y, batch_size=100000, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=822, shape=(1000,), dtype=float32, numpy=\n",
       "array([1.21238232e+01, 1.00705922e-01, 7.64667285e+03, 3.18914962e+00,\n",
       "       1.57489258e+04, 2.03829758e+02, 9.40464878e+00, 1.35461194e-02,\n",
       "       2.55139014e+03, 5.43421484e-04, 1.48330480e-01, 2.06514938e+02,\n",
       "       2.50184769e-03, 4.73372488e-08, 8.23575234e+04, 1.32114947e+00,\n",
       "       6.72494507e+01, 6.96377600e+06, 5.32422920e+07, 5.04576117e-02,\n",
       "       8.25678329e+01, 1.77305031e+01, 6.16659641e+00, 2.71555638e+00,\n",
       "       1.32029236e+02, 7.03650434e-03, 3.89921808e+00, 8.87841523e-01,\n",
       "       1.82209956e-03, 1.01331357e+04, 2.46027417e+03, 1.63398814e+00,\n",
       "       3.79049349e+00, 6.69985504e+01, 4.67193685e-02, 1.36680186e+00,\n",
       "       1.48160279e+00, 2.11490967e+02, 1.00911297e-01, 2.24391068e-03,\n",
       "       2.54644629e+03, 7.50159025e-01, 4.95267175e-02, 3.22795331e-01,\n",
       "       3.65319276e+00, 6.21352673e+00, 3.28687575e+06, 2.36122292e-02,\n",
       "       4.89925499e+01, 4.10976142e-01, 3.38280737e-01, 4.58471295e-05,\n",
       "       2.90678040e+02, 4.54521250e+05, 1.07781120e+02, 5.13508272e+00,\n",
       "       2.68534393e+01, 1.53628480e+00, 7.81945801e+03, 4.85940633e-04,\n",
       "       2.65699974e-03, 3.02527871e+04, 4.00659100e+06, 6.74864149e+00,\n",
       "       1.26677811e+00, 5.79297546e+02, 3.11141753e+00, 1.20995293e+02,\n",
       "       2.31835098e+01, 8.33942108e+01, 3.76424380e-03, 6.50204301e-01,\n",
       "       3.16835766e+01, 8.10061230e+03, 2.54824829e+00, 3.19409542e+01,\n",
       "       1.73693665e+02, 3.13291430e-01, 7.60224243e+02, 3.19409696e-03,\n",
       "       9.59680974e-01, 6.69588521e-03, 1.06719116e+02, 1.31221771e+00,\n",
       "       2.19598281e+04, 7.83036350e+06, 1.23896509e-01, 7.42196143e-02,\n",
       "       3.01849915e+02, 1.56482443e-01, 1.19458222e+00, 8.54070053e+01,\n",
       "       1.33229300e+06, 6.99379453e+04, 1.30340442e+03, 7.50359058e+00,\n",
       "       3.06081724e+00, 3.43076010e-07, 7.25224891e-05, 5.33408400e+06,\n",
       "       6.93484375e+03, 1.70020691e+02, 6.19160049e-02, 4.45438549e-03,\n",
       "       1.00785240e+07, 6.04195297e-01, 1.48834906e+01, 1.14615455e-01,\n",
       "       1.44399710e-05, 2.62065816e+00, 9.00017548e+00, 3.01694460e-02,\n",
       "       9.43664000e+06, 6.12054138e+02, 2.22701110e-05, 1.73381882e+02,\n",
       "       1.24236317e+01, 1.33694649e-01, 7.06569910e+00, 6.01221289e+03,\n",
       "       6.95278309e-03, 2.74486840e-03, 4.19910840e+03, 1.29501214e-02,\n",
       "       2.72883195e-03, 1.09432405e-03, 2.53378594e+05, 3.06383729e+00,\n",
       "       8.32294128e+02, 9.31248474e+02, 1.66292297e+02, 2.57591516e-01,\n",
       "       1.69674645e-03, 5.14766479e+02, 8.28659832e-02, 2.01311186e-01,\n",
       "       9.66337044e-03, 3.21845934e-02, 1.11921282e+01, 1.63142212e+02,\n",
       "       1.67118609e-02, 4.23353481e+00, 1.73314109e-01, 1.14580967e+04,\n",
       "       4.01538223e-01, 4.78563934e+02, 7.54859388e-01, 5.78164844e+03,\n",
       "       1.04213943e+01, 2.58385390e-01, 4.43397560e+01, 1.10629616e+01,\n",
       "       5.70817322e+02, 2.31624939e+02, 1.19084702e+01, 2.13766079e-02,\n",
       "       5.96104711e-02, 9.97916698e-01, 3.48044019e+03, 1.63944500e+05,\n",
       "       3.32865944e+01, 1.05344515e+01, 2.48581260e-01, 2.37234009e+03,\n",
       "       2.31282787e+01, 4.98729541e+03, 1.99132730e-04, 1.53520588e+06,\n",
       "       4.01469357e-02, 1.66502876e+01, 1.98271293e-02, 3.53083014e-01,\n",
       "       1.96493411e+00, 7.06821289e+02, 1.67848531e+05, 1.31808748e+01,\n",
       "       2.01551544e+02, 1.04238086e+05, 1.09522184e-03, 1.21570933e+00,\n",
       "       2.76404736e+08, 3.10939781e+05, 1.32010961e+00, 5.81781721e+00,\n",
       "       8.65667403e-01, 5.11756836e+02, 1.58022324e+04, 2.30887405e+02,\n",
       "       2.33370352e+00, 2.66938877e+00, 1.97979406e-01, 1.07096179e+03,\n",
       "       1.04481041e-01, 1.30253032e-01, 3.27497253e+01, 1.57601709e+03,\n",
       "       2.85118237e+03, 5.03927078e+01, 2.99061401e+02, 9.86031294e-01,\n",
       "       9.49530888e+00, 8.05671204e+02, 7.01692551e-02, 1.15807379e-04,\n",
       "       6.04310110e-02, 6.88985527e-01, 1.43938332e+01, 5.56877279e+00,\n",
       "       5.28665585e-03, 2.58916125e+06, 3.91276031e+02, 7.39109874e-01,\n",
       "       6.36539844e+04, 1.66922361e-02, 3.54791671e-01, 5.25366217e-02,\n",
       "       2.12344208e+01, 9.42374756e+02, 5.76840401e+01, 8.34519323e-03,\n",
       "       8.70493793e+00, 2.97796448e+02, 1.18612354e+04, 1.01197309e+01,\n",
       "       8.55299707e+03, 2.57693965e+04, 3.52561469e+05, 5.41517064e-02,\n",
       "       2.93910086e-01, 5.37716150e-01, 2.27278173e-02, 2.79567760e+07,\n",
       "       2.86738133e+00, 3.87270272e-01, 9.21010692e-03, 1.45888781e+09,\n",
       "       1.69556204e-03, 1.13233162e+02, 1.37229033e+04, 7.35672982e-03,\n",
       "       1.42663745e-02, 4.78936285e-02, 1.57122386e+00, 1.89754410e-05,\n",
       "       2.42504507e-06, 2.41486618e+02, 2.25635938e+05, 4.01054764e+01,\n",
       "       1.92123116e-03, 1.33789110e+01, 7.37707250e+06, 9.97894478e+00,\n",
       "       4.16411981e-02, 2.42448226e-01, 1.36508361e-01, 3.51001205e+01,\n",
       "       6.52253181e-02, 1.29126266e-01, 1.53188631e-02, 1.09375046e+02,\n",
       "       5.22182568e+03, 2.20460879e+04, 2.20660801e+04, 4.72470140e+00,\n",
       "       1.96476860e-04, 1.39837217e+01, 6.87378943e-01, 2.00401973e-02,\n",
       "       1.73757412e-02, 2.16113657e-01, 2.29706512e+02, 1.24043800e+02,\n",
       "       2.71298809e+01, 4.70296094e+04, 1.74096715e+00, 1.44701233e-04,\n",
       "       7.55184692e-06, 1.88673858e-03, 4.19268431e-03, 2.17056469e-04,\n",
       "       1.16324213e-06, 1.41344727e+02, 3.51519197e-01, 3.26020704e-08,\n",
       "       1.30174376e-04, 5.97993494e-04, 1.20529203e+01, 2.52127107e-02,\n",
       "       6.47964478e-02, 1.87600046e-01, 1.23864927e+01, 2.18100667e+00,\n",
       "       3.56404375e+04, 9.67936066e-04, 1.69931855e-02, 8.35637988e+03,\n",
       "       9.55548950e+02, 3.06722876e+03, 3.24891074e+04, 4.00552154e-01,\n",
       "       3.57057056e+03, 1.24640627e+01, 5.43454053e+03, 3.30964988e-03,\n",
       "       3.16280781e+05, 6.69018812e+05, 4.08303436e-07, 4.96693428e-05,\n",
       "       4.99293633e+04, 5.37921069e-03, 2.56953573e+00, 3.70924503e-01,\n",
       "       1.54234096e-02, 1.45789980e+04, 4.74098961e-05, 5.84420413e-05,\n",
       "       1.08579636e+01, 1.39620350e+07, 6.14183228e+02, 8.54961225e-04,\n",
       "       1.54015133e-02, 1.29131789e-04, 3.96095154e+02, 1.84886038e+00,\n",
       "       8.25125200e+07, 1.24686390e-01, 1.53736556e+00, 7.55102634e-01,\n",
       "       1.29018368e+09, 6.00048304e-01, 3.76379229e-02, 2.66716465e+04,\n",
       "       9.85098047e+04, 3.22176784e-01, 4.75780201e+00, 2.37146281e-02,\n",
       "       1.40255142e+02, 2.82545406e+05, 2.93142784e-06, 8.39699631e+01,\n",
       "       3.64684552e-01, 6.74018636e-04, 1.29944742e+00, 1.56503871e-01,\n",
       "       7.79489756e-01, 4.57620621e-03, 2.31038019e-01, 3.21722217e-02,\n",
       "       1.28734602e+05, 8.47800636e+00, 5.44006375e+05, 2.68642069e-03,\n",
       "       5.97843875e+05, 1.55795831e-02, 4.54936670e+03, 3.09063983e+00,\n",
       "       5.68768531e-02, 5.15143013e+00, 6.91112900e+00, 1.98732262e+01,\n",
       "       2.81009683e-03, 3.49282885e+00, 4.63759691e-01, 2.93701416e+02,\n",
       "       1.06181279e-02, 1.87721729e-01, 1.07495260e+00, 5.62279248e+03,\n",
       "       1.41482716e-02, 3.69946469e+05, 8.71295989e-01, 8.86115375e+05,\n",
       "       1.85140488e+04, 1.93311438e-01, 1.65864629e+04, 8.95135880e+01,\n",
       "       6.48904000e+05, 2.85437495e-01, 1.45725159e+03, 1.29857764e+03,\n",
       "       1.19087832e+04, 5.46985539e-04, 6.04694128e-01, 9.20441223e+02,\n",
       "       7.58737230e+00, 1.64291489e+00, 7.11482227e-01, 2.96688962e+00,\n",
       "       5.76656389e+00, 6.54431934e+03, 3.28728065e+01, 5.81481476e+01,\n",
       "       2.51597905e+00, 3.23673747e-02, 2.69968659e-05, 5.96701367e+03,\n",
       "       4.70728064e+00, 1.49319216e-03, 7.43670642e-01, 8.90583396e-02,\n",
       "       4.92858848e+08, 4.96068060e-01, 1.10868931e-01, 1.12180054e+00,\n",
       "       1.27576932e-03, 6.72556972e-03, 3.55602188e+04, 3.83083945e+04,\n",
       "       1.93155575e+01, 1.04799158e+03, 6.22997070e+02, 8.42013086e+03,\n",
       "       2.16384961e+04, 7.17179418e-01, 2.90329041e+02, 8.55358597e-03,\n",
       "       3.72210452e-05, 4.76140372e-09, 4.43206982e+03, 2.20318139e-02,\n",
       "       6.90244050e+06, 1.91348651e-03, 1.13134850e+02, 1.39351416e+01,\n",
       "       4.10679770e+00, 2.36624619e+02, 1.29912510e+01, 4.15958390e-02,\n",
       "       5.07841748e+03, 4.11357727e+02, 5.47996902e+01, 6.28972828e-01,\n",
       "       1.19192949e+04, 2.04005893e-02, 3.73141562e+04, 1.32499191e+02,\n",
       "       8.12368453e-01, 9.73481172e+04, 1.37273759e-01, 3.14997919e-02,\n",
       "       5.55430412e+01, 4.12812196e-02, 1.75231685e-06, 6.37558228e+02,\n",
       "       1.09458566e+00, 2.31347550e-02, 1.57006799e+03, 3.99230629e-01,\n",
       "       2.68647480e+01, 3.06363583e+00, 1.83959453e+05, 9.79872852e+03,\n",
       "       9.26202637e+03, 2.90776435e-02, 2.67785583e-02, 7.56540451e+01,\n",
       "       3.99769867e+02, 1.84781094e+01, 4.94237304e-01, 1.21975169e-01,\n",
       "       1.71953949e+02, 3.99431866e-03, 4.25785729e-05, 4.05263036e-01,\n",
       "       1.88838547e+02, 1.13468042e+03, 1.40145445e+01, 9.57158051e+01,\n",
       "       1.56391132e+00, 1.42322788e-02, 8.53351727e-02, 7.01760113e-01,\n",
       "       1.53550820e-03, 1.12186312e+05, 5.84212732e+00, 4.13666974e-04,\n",
       "       3.49036455e-02, 4.32651855e+02, 1.52233337e+02, 1.25149221e+01,\n",
       "       1.57566047e+00, 1.79666076e-02, 2.33424102e+04, 5.05334160e+07,\n",
       "       6.41852140e-01, 8.04263916e+03, 1.22471130e+02, 1.56843245e+00,\n",
       "       3.24812211e+09, 4.44555059e-02, 3.77421808e+00, 1.23583986e-05,\n",
       "       8.93439770e-01, 1.19560754e+03, 1.00668381e+02, 2.86354688e+03,\n",
       "       1.45705283e+04, 2.55011432e-02, 6.20783325e+02, 1.24004111e-01,\n",
       "       8.54140744e-02, 3.27950703e+04, 7.67124748e+00, 9.59793627e-01,\n",
       "       5.56361908e-03, 6.45420551e-01, 1.07721949e-04, 1.90735877e+00,\n",
       "       2.22954987e+02, 1.82086993e-02, 1.28418751e+01, 2.63368011e-01,\n",
       "       5.71254687e-03, 7.17065613e+02, 1.24798869e-04, 1.79896317e+02,\n",
       "       7.52935982e+00, 3.55380923e-02, 1.51141834e+00, 1.57660999e+01,\n",
       "       5.02325537e+03, 8.04682910e+03, 2.40386724e+00, 4.76951573e-05,\n",
       "       2.41607253e-04, 7.42181465e-02, 4.62846016e-04, 1.21517960e+02,\n",
       "       7.55574601e-03, 2.09592896e+01, 2.91494339e+10, 1.97721756e+00,\n",
       "       8.77104553e+02, 3.48909706e-01, 8.01962097e+02, 4.10836372e+01,\n",
       "       4.22985740e-02, 2.54863167e+00, 2.63000522e-02, 2.61989199e-02,\n",
       "       1.69786438e-01, 2.66947240e-01, 3.33238572e-01, 9.33248901e+00,\n",
       "       1.68728984e+04, 6.33156000e+05, 5.27285843e+01, 8.63248688e+05,\n",
       "       1.58824399e-01, 4.77576675e-03, 2.92360156e+04, 2.14833179e+03,\n",
       "       1.70277452e+00, 2.94141197e+00, 2.93911040e-01, 1.10764533e-01,\n",
       "       4.68958906e+04, 6.17933972e-03, 4.62559688e+04, 2.57561919e-06,\n",
       "       1.13939297e+00, 5.63274803e+01, 1.93410075e+06, 1.65839732e-01,\n",
       "       1.34682541e+01, 5.05744696e+00, 1.77759540e+00, 1.39969096e-01,\n",
       "       2.70082832e+04, 2.90584106e+01, 8.22137654e-01, 1.27536658e+03,\n",
       "       3.48523080e-01, 1.66227538e-02, 5.83985209e-01, 1.49810299e-01,\n",
       "       5.28882904e+01, 4.11043500e+05, 4.92753834e-03, 8.34792663e-05,\n",
       "       3.05981655e+01, 1.56121044e+01, 1.11719495e+03, 3.60564014e+03,\n",
       "       1.72103625e-02, 3.19640279e+00, 9.78010864e+01, 5.01376810e-03,\n",
       "       2.11701740e+07, 4.38285759e-04, 2.14088906e+05, 5.67090027e+02,\n",
       "       1.99757109e-04, 9.01981125e+01, 1.80660305e-03, 9.62255061e-01,\n",
       "       5.88537537e+02, 4.49313283e-01, 1.49527664e+01, 3.75653733e-04,\n",
       "       1.01462078e+01, 3.39860469e-02, 2.83834982e+00, 1.31140958e-04,\n",
       "       4.10375488e+02, 3.05294828e-03, 3.39578725e-02, 1.69483399e+00,\n",
       "       2.72047699e+02, 5.37420352e+08, 8.63624763e+00, 2.92415625e+05,\n",
       "       5.75429077e+02, 2.34977036e+01, 9.31130981e+00, 3.52516031e+00,\n",
       "       3.83597690e-05, 2.77670976e+08, 1.77567884e-01, 3.14423066e+04,\n",
       "       1.86655726e-02, 1.33152191e+02, 2.22364231e-03, 8.94583594e+03,\n",
       "       7.62088821e-05, 3.51526719e+05, 1.96144438e+05, 3.80474981e-03,\n",
       "       5.80945320e+01, 6.60848438e+04, 8.30551289e-05, 5.54041982e-01,\n",
       "       1.07083888e-05, 1.73573360e+01, 2.33129950e+06, 6.75729980e+03,\n",
       "       2.62717652e+00, 4.77197933e+00, 1.52969739e+03, 3.28530945e+02,\n",
       "       1.49327172e-02, 6.58559054e-03, 1.53451494e+04, 8.55372238e+01,\n",
       "       7.59595032e+02, 7.17882462e+01, 7.81204691e-03, 1.09586536e+03,\n",
       "       8.40134976e+08, 3.56975896e-03, 5.11980724e+00, 7.37556152e+01,\n",
       "       1.49449822e-03, 5.17580867e-01, 5.68833842e-04, 4.95669572e-03,\n",
       "       4.41700310e-01, 1.40299012e+06, 6.16807878e-01, 5.22430171e-04,\n",
       "       5.18996468e+01, 4.91186753e-02, 3.07679534e+00, 9.70749084e+02,\n",
       "       2.71933125e+06, 3.04415338e-02, 4.47954796e-03, 3.00238803e-02,\n",
       "       1.68367639e-01, 9.69382527e-04, 8.88432190e-02, 2.50170825e+03,\n",
       "       6.47919062e+05, 2.08108459e+02, 4.67519520e+07, 3.96273332e-03,\n",
       "       4.33198929e-01, 4.57362732e+02, 1.28278943e+03, 1.36442000e+08,\n",
       "       3.38604021e+00, 9.45035601e-04, 1.11673906e+04, 6.42858375e+05,\n",
       "       1.05378485e+00, 5.85044992e+08, 3.30679305e-02, 8.15177673e+02,\n",
       "       2.65660667e-04, 1.73378691e-01, 1.03593073e+10, 2.35395837e+00,\n",
       "       2.41872171e-04, 2.55161744e+08, 2.76434720e-01, 8.70629191e-01,\n",
       "       7.96595337e+02, 1.47875586e+03, 6.37338012e-02, 4.33256592e+03,\n",
       "       1.93491094e-02, 2.12084814e+03, 7.42186010e-02, 5.47862500e+06,\n",
       "       1.91173225e-03, 5.79370135e-05, 2.88908813e+02, 2.95881787e-03,\n",
       "       9.00863552e+00, 3.53879852e+02, 1.29944688e+06, 1.22001382e+09,\n",
       "       4.59634933e+01, 3.07014008e+01, 1.14256719e+05, 3.46424609e-01,\n",
       "       2.08018017e+01, 7.28809131e+03, 3.51826847e-03, 1.44995935e-03,\n",
       "       5.78391016e-01, 1.85191619e+00, 2.19059777e+00, 1.68717114e+03,\n",
       "       4.86777984e-02, 9.10254974e+01, 3.63259400e+06, 1.18566758e+04,\n",
       "       1.64120609e-03, 7.04835132e-02, 1.21368752e+02, 7.49000320e+01,\n",
       "       8.46263611e+02, 2.15129321e+03, 1.50322479e+02, 4.74525928e+03,\n",
       "       1.10476738e+02, 1.17041540e+00, 2.78627723e-01, 9.51506644e-02,\n",
       "       1.68340117e-01, 1.25104416e-04, 3.21075786e-05, 4.47326200e-03,\n",
       "       7.04276085e+00, 8.12715703e+04, 6.88886871e+01, 1.12855630e-02,\n",
       "       5.58816875e+05, 6.28875351e+01, 2.32149094e+02, 6.70668884e+02,\n",
       "       4.42160554e-02, 1.17195415e+00, 2.18311285e-07, 3.13530240e-04,\n",
       "       1.97353467e-01, 3.48361237e+02, 1.38518164e+04, 1.60412407e+01,\n",
       "       1.64354721e-03, 9.36502832e+03, 1.81395983e-04, 7.55719189e+03,\n",
       "       3.76635625e+05, 1.05030108e-02, 3.88550385e+02, 9.97437350e-03,\n",
       "       6.66717224e+02, 2.61332375e+05, 7.20260193e+02, 2.78490619e-03,\n",
       "       5.92118442e-01, 1.33195445e-01, 3.77353193e-04, 6.61871062e+05,\n",
       "       1.70955524e+01, 2.79531693e+00, 7.73214436e+00, 3.21621819e+01,\n",
       "       3.82017754e-02, 9.26147995e+01, 2.04043288e-04, 9.37156641e+03,\n",
       "       6.26594648e-02, 1.40956715e-02, 2.21158032e+03, 1.14362493e-01,\n",
       "       1.41175365e+01, 8.33897656e+03, 8.51334453e+04, 7.32814121e+00,\n",
       "       3.35332666e+03, 2.89990366e-01, 6.24434033e-05, 3.86754200e+07,\n",
       "       2.87371278e+00, 2.27584504e-03, 1.27259570e+04, 1.45662537e+03,\n",
       "       3.29397182e-04, 1.63133259e+01, 1.34208618e-04, 4.24758577e+00,\n",
       "       3.99678223e+02, 1.15959030e-02, 2.42609676e-04, 8.46464038e-01,\n",
       "       4.88661445e+04, 2.99168736e-01, 9.37128353e+00, 8.69499707e+03,\n",
       "       1.20554431e+03, 1.03516521e+01, 4.31870039e+04, 3.98998985e+01,\n",
       "       1.33106830e+07, 6.23433398e+03, 1.16774140e+07, 1.88812852e+04,\n",
       "       1.48982310e-03, 2.89946771e-03, 5.30796349e-01, 1.11817727e-02,\n",
       "       9.80166495e-02, 6.11435948e-03, 3.24377022e+01, 8.45599556e+00,\n",
       "       1.05338326e+01, 1.02074452e-01, 2.32916214e+02, 9.71830273e+00,\n",
       "       1.04813409e+00, 3.01983500e+00, 1.18741584e+00, 3.52331177e+02,\n",
       "       2.33570465e+02, 8.30191839e-03, 2.85636234e+00, 1.26731625e+05,\n",
       "       8.13634545e-02, 4.84587288e+01, 6.73675090e-02, 6.79119600e+07,\n",
       "       3.61501000e+05, 2.31491178e-02, 9.08610178e-04, 7.30368408e+02,\n",
       "       3.21420655e-03, 1.66648840e+07, 1.65881767e+01, 9.20074081e+00,\n",
       "       5.17958164e-01, 7.64623657e-03, 3.35770869e+00, 4.12892866e+00,\n",
       "       4.21372500e+04, 1.73291907e-01, 7.02970520e+02, 3.01526226e-02,\n",
       "       3.40555656e+05, 3.75389633e+01, 2.81423405e-02, 1.23088245e+01,\n",
       "       1.05402526e-02, 4.64875204e-03, 5.14557678e-03, 3.30244893e-06,\n",
       "       3.24998656e+05, 2.67182838e+10, 2.80268192e-02, 9.79750562e+05,\n",
       "       3.87126021e-03, 2.61634678e-01, 7.21657136e-03, 3.43541838e-02,\n",
       "       4.05005738e-02, 2.19987198e+02, 2.11154819e+00, 5.45993103e+02,\n",
       "       1.37453929e-01, 1.23930603e+03, 2.60386448e-02, 1.43381685e-01,\n",
       "       9.30675655e-04, 3.33498508e-01, 2.21980839e+01, 1.06268631e+02,\n",
       "       4.12046623e+00, 9.23124433e-01, 5.52982129e-02, 8.29212646e+02,\n",
       "       1.42746094e+03, 3.04760673e-04, 3.30915275e+06, 2.80686665e+00,\n",
       "       7.98120000e+07, 4.74266434e+00, 3.56200896e-02, 8.68240356e-01,\n",
       "       1.59228302e+02, 9.78291168e+01, 7.56027266e+04, 1.24214101e+00,\n",
       "       1.85950860e-01, 1.15888567e+01, 9.58501756e-01, 2.84997467e-03,\n",
       "       4.84679341e-02, 7.04358936e+03, 4.57715876e-02, 5.24570129e+02,\n",
       "       1.36274242e+01, 1.06656736e+08, 3.79375211e-04, 8.10312629e-01,\n",
       "       9.89240000e+05, 6.36089850e+06, 5.28700049e+03, 1.29254234e+00,\n",
       "       2.91074842e-01, 8.30186797e+04, 1.22479515e+01, 4.10754718e-02,\n",
       "       2.14162555e-05, 2.10353836e-01, 6.94046631e+01, 1.93511459e+02,\n",
       "       7.09513123e+02, 6.19114136e+02, 2.31442094e-01, 9.20495484e-03,\n",
       "       7.46977236e-08, 5.85942812e+05, 7.54403125e+05, 1.04695715e-01,\n",
       "       9.21646667e+02, 1.23473396e+01, 2.00546055e+01, 9.91715336e+00,\n",
       "       1.87900965e-03, 2.40009911e-02, 2.96549892e+00, 1.52139877e+02,\n",
       "       5.58502031e+04, 6.64410517e-02, 4.04847750e+05, 3.28755035e+02,\n",
       "       4.67943799e+03, 8.08972656e+04, 5.16569614e-01, 6.26817405e-01,\n",
       "       1.46273203e+04, 4.95864870e-03, 1.84307605e-01, 1.21391368e+00,\n",
       "       2.08109189e-02, 2.11803579e+00, 4.31535423e-01, 3.26088935e-01,\n",
       "       6.31851816e+00, 1.84251320e+07, 6.88494730e+00, 6.60649728e+08,\n",
       "       4.35619010e-03, 2.67300010e+00, 3.75468063e+00, 2.72940975e-02,\n",
       "       8.49438705e+01, 9.07766247e+00, 1.62410036e-01, 5.03407046e-02,\n",
       "       1.63425859e-02, 9.01153374e+00, 2.96151312e+05, 5.19244957e+01,\n",
       "       2.36635859e+04, 6.72061777e+00, 2.48660508e-04, 1.50573718e+03,\n",
       "       2.27862727e-02, 1.04889026e+03, 8.87645156e+04, 1.42012775e-01,\n",
       "       1.34496045e+03, 1.91926706e+00, 7.40017414e+00, 5.56996289e+03,\n",
       "       4.95242596e+00, 1.04227876e-02, 4.53051224e+01, 1.97493906e+05,\n",
       "       2.44350791e+00, 6.18414941e+03, 2.69114742e+01, 2.66217598e+04,\n",
       "       5.31368438e+05, 2.77865601e+03, 8.00565567e+01, 1.80703457e-02],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_distr.variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=824, shape=(1000,), dtype=float32, numpy=\n",
       "array([5.39192915e+00, 9.40134972e-02, 2.61385040e+02, 2.01179886e+00,\n",
       "       1.83725555e+02, 2.39086666e+01, 1.71441627e+00, 1.30386744e-02,\n",
       "       8.63368378e+01, 5.41332411e-04, 1.41170457e-01, 3.30959282e+01,\n",
       "       2.48523825e-03, 4.73338169e-08, 8.45050842e+02, 8.71967971e-01,\n",
       "       2.12845192e+01, 7.70625244e+03, 1.97486152e+04, 4.95060720e-02,\n",
       "       1.70164757e+01, 6.84960270e+00, 2.24802613e+00, 1.58621025e+00,\n",
       "       2.24217052e+01, 7.00184191e-03, 2.31625009e+00, 6.30251825e-01,\n",
       "       1.82117056e-03, 2.63476562e+02, 1.24819069e+02, 1.34678996e+00,\n",
       "       1.59668016e+00, 1.40467587e+01, 4.60770465e-02, 7.82155454e-01,\n",
       "       1.05084479e+00, 2.00056953e+01, 7.83467814e-02, 2.16445350e-03,\n",
       "       1.03910805e+02, 6.58941627e-01, 4.84120101e-02, 1.90160573e-01,\n",
       "       2.22222304e+00, 2.88203239e+00, 5.04907129e+03, 2.32535619e-02,\n",
       "       8.42647743e+00, 3.56983066e-01, 3.10838521e-01, 4.55867739e-05,\n",
       "       1.67614784e+01, 2.06810327e+03, 2.31319218e+01, 3.19660497e+00,\n",
       "       8.31764126e+00, 9.78919506e-01, 2.97189636e+02, 4.82383533e-04,\n",
       "       2.60249618e-03, 5.18494934e+02, 4.15436377e+03, 3.95768023e+00,\n",
       "       1.05722213e+00, 6.09283218e+01, 1.84433007e+00, 2.40540218e+01,\n",
       "       6.81178856e+00, 2.17611198e+01, 2.66437745e-03, 5.37529111e-01,\n",
       "       1.15067406e+01, 1.91868622e+02, 1.82246232e+00, 1.09998760e+01,\n",
       "       3.74261971e+01, 2.81704575e-01, 3.87003174e+01, 3.10351816e-03,\n",
       "       7.98622072e-01, 6.59399247e-03, 1.37105742e+01, 9.88813102e-01,\n",
       "       4.00913849e+02, 8.16560547e+03, 1.15466081e-01, 7.27680326e-02,\n",
       "       3.13642693e+01, 1.43493220e-01, 8.22864234e-01, 1.56453285e+01,\n",
       "       3.80989453e+03, 7.25324280e+02, 1.02502151e+02, 4.82202864e+00,\n",
       "       1.70318747e+00, 3.43067740e-07, 7.25080099e-05, 7.24195020e+03,\n",
       "       1.98339890e+02, 2.63301773e+01, 5.37173636e-02, 4.44520777e-03,\n",
       "       9.84110742e+03, 3.61491531e-01, 4.72261429e+00, 1.07426099e-01,\n",
       "       1.44349751e-05, 1.21450281e+00, 4.04980135e+00, 2.81268675e-02,\n",
       "       8.93395410e+03, 5.73917122e+01, 2.22433300e-05, 3.08882866e+01,\n",
       "       4.67035389e+00, 1.29071653e-01, 2.94130278e+00, 1.97252655e+02,\n",
       "       6.90059550e-03, 2.58833007e-03, 1.40010574e+02, 1.25887897e-02,\n",
       "       2.70055956e-03, 1.07004447e-03, 1.27735779e+03, 4.56312120e-01,\n",
       "       6.18050919e+01, 8.21872940e+01, 1.80177670e+01, 2.09394127e-01,\n",
       "       1.69391313e-03, 5.86972466e+01, 7.99730942e-02, 1.26234040e-01,\n",
       "       9.09844507e-03, 3.05040982e-02, 4.92481184e+00, 1.99177532e+01,\n",
       "       1.65024083e-02, 2.44263768e+00, 1.35711148e-01, 2.77627319e+02,\n",
       "       3.63562495e-01, 4.34961853e+01, 6.66827798e-01, 1.84928696e+02,\n",
       "       3.73233175e+00, 2.21237391e-01, 9.83496094e+00, 3.91823864e+00,\n",
       "       1.96955128e+01, 3.27034340e+01, 6.30595255e+00, 2.04079375e-02,\n",
       "       5.72345294e-02, 6.19248211e-01, 1.48161804e+02, 1.04278870e+03,\n",
       "       1.02889624e+01, 5.26072693e+00, 2.11696476e-01, 1.05631828e+02,\n",
       "       9.97549915e+00, 1.02906349e+02, 1.98169189e-04, 3.82835718e+03,\n",
       "       3.41141224e-02, 4.22090912e+00, 1.95052307e-02, 3.29377711e-01,\n",
       "       1.57111132e+00, 5.31585808e+01, 9.72072266e+02, 6.27275419e+00,\n",
       "       3.29505692e+01, 3.62231537e+02, 1.09136687e-03, 9.50668931e-01,\n",
       "       6.45984961e+04, 1.69881360e+03, 8.78105938e-01, 3.47198534e+00,\n",
       "       7.59561658e-01, 5.08908272e+01, 3.98158020e+02, 2.96208820e+01,\n",
       "       6.58232629e-01, 1.60802889e+00, 1.84769303e-01, 5.24653778e+01,\n",
       "       9.50387865e-02, 1.18665189e-01, 6.85342121e+00, 1.00566338e+02,\n",
       "       9.59180145e+01, 9.02629375e+00, 3.49377708e+01, 5.55566907e-01,\n",
       "       5.09722996e+00, 6.22325325e+01, 6.58196732e-02, 1.15788622e-04,\n",
       "       5.53608313e-02, 5.68223715e-01, 7.04448605e+00, 2.92674184e+00,\n",
       "       4.48738737e-03, 4.82461768e+03, 4.25920067e+01, 6.10454857e-01,\n",
       "       5.02579987e+02, 1.66119002e-02, 1.59351602e-01, 5.12728579e-02,\n",
       "       7.18267250e+00, 7.83565216e+01, 1.70619507e+01, 8.21996015e-03,\n",
       "       5.16001987e+00, 2.78473377e+01, 8.54242554e+01, 3.80843711e+00,\n",
       "       2.25932953e+02, 4.29223053e+02, 1.68295129e+03, 3.60163040e-02,\n",
       "       2.68847018e-01, 4.47690338e-01, 2.25924198e-02, 1.12820479e+04,\n",
       "       1.63494492e+00, 3.65451783e-01, 9.13580041e-03, 1.39826031e+05,\n",
       "       1.68910471e-03, 2.21429977e+01, 2.11771851e+02, 7.32282596e-03,\n",
       "       1.42039666e-02, 4.42770980e-02, 1.11565721e+00, 1.89577204e-05,\n",
       "       2.42338433e-06, 3.26350708e+01, 1.31951013e+03, 1.14719687e+01,\n",
       "       1.90712628e-03, 6.39257717e+00, 8.31135645e+03, 3.77456021e+00,\n",
       "       4.03503701e-02, 1.74737632e-01, 1.24523878e-01, 1.11828709e+01,\n",
       "       5.96675165e-02, 7.15074316e-02, 1.52230011e-02, 1.52347174e+01,\n",
       "       1.30456970e+02, 3.25639801e+02, 4.03853271e+02, 3.13209724e+00,\n",
       "       1.95375382e-04, 6.49858999e+00, 5.68993449e-01, 1.82322264e-02,\n",
       "       1.71573404e-02, 6.84333742e-02, 3.66205673e+01, 1.92543411e+01,\n",
       "       6.52638578e+00, 5.34276917e+02, 9.06965077e-01, 1.43841156e-04,\n",
       "       7.55089104e-06, 1.87177048e-03, 4.14017355e-03, 2.01831732e-04,\n",
       "       1.15872365e-06, 2.02654457e+01, 2.64796883e-01, 3.26015623e-08,\n",
       "       1.30155313e-04, 5.92597586e-04, 4.89833069e+00, 2.38054972e-02,\n",
       "       6.22228198e-02, 1.27284989e-01, 3.71103239e+00, 1.47273743e+00,\n",
       "       3.05259583e+02, 9.35313350e-04, 1.66946482e-02, 2.49406616e+02,\n",
       "       7.42598953e+01, 1.07633987e+02, 4.38080261e+02, 3.62205893e-01,\n",
       "       1.57271423e+02, 4.74258566e+00, 1.32423309e+02, 3.28901340e-03,\n",
       "       1.53662000e+03, 2.53402026e+03, 4.08266061e-07, 4.93139923e-05,\n",
       "       7.12711121e+02, 5.32034272e-03, 1.70995164e+00, 3.23797494e-01,\n",
       "       1.52862417e-02, 2.15472153e+02, 4.72107713e-05, 5.83729307e-05,\n",
       "       5.25547886e+00, 9.80292480e+03, 3.44307938e+01, 8.00789450e-04,\n",
       "       1.46665098e-02, 1.28902509e-04, 5.19271431e+01, 1.52590775e+00,\n",
       "       2.04446641e+04, 1.15306161e-01, 1.01763380e+00, 6.46541178e-01,\n",
       "       1.04892883e+05, 4.95329589e-01, 3.56728621e-02, 3.28974152e+02,\n",
       "       7.71841980e+02, 2.41019711e-01, 3.17042947e+00, 2.34249867e-02,\n",
       "       2.01663551e+01, 1.47819507e+03, 2.92819618e-06, 1.48339109e+01,\n",
       "       1.97573856e-01, 6.72109716e-04, 8.46271336e-01, 1.34692729e-01,\n",
       "       6.29080117e-01, 4.55698743e-03, 2.15167135e-01, 3.13416645e-02,\n",
       "       9.18341553e+02, 2.69532108e+00, 1.63827246e+03, 2.67160055e-03,\n",
       "       1.96405408e+03, 1.54835526e-02, 1.94477020e+02, 1.47965276e+00,\n",
       "       5.14420532e-02, 2.20755267e+00, 2.23729157e+00, 8.69484901e+00,\n",
       "       2.60973442e-03, 2.28207922e+00, 4.11905468e-01, 4.32888794e+01,\n",
       "       1.04449755e-02, 1.34469092e-01, 7.30380535e-01, 1.96979706e+02,\n",
       "       1.39983343e-02, 1.97811975e+03, 7.24093139e-01, 3.39246265e+03,\n",
       "       4.44349640e+02, 1.78689897e-01, 1.66939117e+02, 1.47921638e+01,\n",
       "       2.23734985e+03, 2.25759014e-01, 8.30236206e+01, 9.67767715e+01,\n",
       "       2.82182434e+02, 5.44220209e-04, 5.49171269e-01, 7.53262024e+01,\n",
       "       3.74832058e+00, 1.25004482e+00, 5.93343258e-01, 1.58669114e+00,\n",
       "       2.97585058e+00, 2.06837341e+02, 1.00791616e+01, 1.73941250e+01,\n",
       "       1.48085070e+00, 3.15904580e-02, 2.69741740e-05, 1.33669235e+02,\n",
       "       1.85738218e+00, 1.47714512e-03, 6.47569418e-01, 7.74353147e-02,\n",
       "       6.27485820e+04, 4.18788850e-01, 1.01666890e-01, 9.90876615e-01,\n",
       "       1.27349014e-03, 6.70571579e-03, 5.44718018e+02, 6.94972046e+02,\n",
       "       8.38570499e+00, 5.04929657e+01, 5.12492523e+01, 1.92145599e+02,\n",
       "       3.48893524e+02, 5.46223938e-01, 2.93402214e+01, 8.50856677e-03,\n",
       "       3.71384522e-05, 4.76137441e-09, 1.88070877e+02, 2.17594635e-02,\n",
       "       7.42567480e+03, 1.90354930e-03, 2.16085796e+01, 6.10760832e+00,\n",
       "       2.39158535e+00, 3.31118240e+01, 6.13074017e+00, 4.01997007e-02,\n",
       "       1.40795395e+02, 6.37650681e+01, 1.53246403e+01, 4.87808317e-01,\n",
       "       1.24999664e+02, 1.95307378e-02, 5.00536346e+02, 2.18283463e+01,\n",
       "       6.41994834e-01, 8.42786987e+02, 1.25471503e-01, 3.06090843e-02,\n",
       "       1.32600212e+01, 4.08034921e-02, 1.75217531e-06, 2.77332726e+01,\n",
       "       9.18982387e-01, 1.82507019e-02, 9.31533737e+01, 3.69624346e-01,\n",
       "       4.80735636e+00, 1.78042114e+00, 1.05979541e+03, 2.18789124e+02,\n",
       "       1.75539276e+02, 2.88490225e-02, 2.65901126e-02, 1.41010771e+01,\n",
       "       4.37427826e+01, 7.92967701e+00, 3.80247205e-01, 1.18291274e-01,\n",
       "       1.75637875e+01, 3.90812010e-03, 4.25743638e-05, 3.50898862e-01,\n",
       "       3.18074093e+01, 4.29555244e+01, 6.08352137e+00, 2.16280365e+01,\n",
       "       8.69294345e-01, 1.40500097e-02, 6.31711334e-02, 6.11756802e-01,\n",
       "       1.50536699e-03, 7.05710815e+02, 2.51062346e+00, 4.13195405e-04,\n",
       "       3.39769274e-02, 5.04575119e+01, 5.64382172e+00, 5.38003254e+00,\n",
       "       1.24207151e+00, 1.78664234e-02, 4.09387787e+02, 2.14426152e+04,\n",
       "       5.79014480e-01, 2.24217377e+02, 2.45443192e+01, 9.91484880e-01,\n",
       "       1.91473531e+05, 4.01612930e-02, 2.49339557e+00, 1.23006566e-05,\n",
       "       7.63404667e-01, 6.74261017e+01, 1.74637680e+01, 9.61939316e+01,\n",
       "       2.53178024e+02, 2.42275316e-02, 5.06314316e+01, 1.15656942e-01,\n",
       "       7.74246827e-02, 3.70971252e+02, 3.81611943e+00, 7.47965872e-01,\n",
       "       5.53333433e-03, 4.09557790e-01, 1.07525644e-04, 1.55122471e+00,\n",
       "       4.05271530e+01, 1.77190993e-02, 5.62578964e+00, 2.44806170e-01,\n",
       "       4.84418264e-03, 4.48841515e+01, 1.24777143e-04, 1.99682560e+01,\n",
       "       2.24825311e+00, 3.46282758e-02, 1.09868264e+00, 6.77391100e+00,\n",
       "       1.99437759e+02, 2.68632904e+02, 1.66151702e+00, 4.76827663e-05,\n",
       "       2.37053304e-04, 7.34753534e-02, 4.62287484e-04, 2.95924988e+01,\n",
       "       7.40357814e-03, 8.10009003e+00, 6.06367125e+05, 1.21619785e+00,\n",
       "       7.84761658e+01, 2.89256692e-01, 5.04140968e+01, 1.12207260e+01,\n",
       "       4.14756201e-02, 1.50261867e+00, 2.55625155e-02, 2.55131945e-02,\n",
       "       1.58564463e-01, 2.50706583e-01, 3.13999742e-01, 4.31723785e+00,\n",
       "       2.87998688e+02, 2.32468701e+03, 1.47803392e+01, 2.03882446e+03,\n",
       "       1.48173839e-01, 4.74054087e-03, 5.55542480e+02, 6.87659607e+01,\n",
       "       5.17387271e-01, 1.94219267e+00, 2.65622675e-01, 1.05542272e-01,\n",
       "       6.00431274e+02, 4.41340543e-03, 6.69823425e+02, 2.57358693e-06,\n",
       "       9.05422390e-01, 1.72555141e+01, 3.46547388e+03, 1.21569201e-01,\n",
       "       5.84733438e+00, 3.35315108e+00, 1.37948108e+00, 1.21836998e-01,\n",
       "       3.90853607e+02, 6.57476473e+00, 5.71179390e-01, 5.48936119e+01,\n",
       "       3.04671109e-01, 1.61682311e-02, 1.31413624e-01, 1.41198471e-01,\n",
       "       1.51547327e+01, 1.91828442e+03, 4.86329570e-03, 8.30657882e-05,\n",
       "       9.02616215e+00, 4.23397255e+00, 6.31453400e+01, 1.54355499e+02,\n",
       "       1.41932527e-02, 2.02601814e+00, 1.69665012e+01, 4.38801851e-03,\n",
       "       1.34341875e+04, 4.37295501e-04, 1.25838940e+03, 3.21297989e+01,\n",
       "       1.99400398e-04, 1.17364855e+01, 1.78462756e-03, 7.36281931e-01,\n",
       "       5.21437988e+01, 3.95488083e-01, 5.40025425e+00, 3.69375164e-04,\n",
       "       3.64497876e+00, 3.25483494e-02, 1.27706695e+00, 1.30816203e-04,\n",
       "       4.42819595e+01, 3.02917068e-03, 3.32736149e-02, 1.20161223e+00,\n",
       "       3.42974014e+01, 7.14650625e+04, 2.80040979e+00, 1.31921729e+03,\n",
       "       3.69633408e+01, 1.00550671e+01, 2.83871984e+00, 2.07256866e+00,\n",
       "       3.83497099e-05, 4.31802031e+04, 1.67507142e-01, 4.36040161e+02,\n",
       "       1.77876689e-02, 2.27918262e+01, 2.18475959e-03, 9.15370026e+01,\n",
       "       7.60164694e-05, 1.91021936e+03, 1.31313489e+03, 3.77591955e-03,\n",
       "       1.56595974e+01, 6.21895386e+02, 8.29931814e-05, 4.90957826e-01,\n",
       "       1.07077331e-05, 6.68749905e+00, 3.65322998e+03, 1.97371063e+02,\n",
       "       1.62490141e+00, 3.23441625e+00, 8.18694839e+01, 3.79053383e+01,\n",
       "       1.48248030e-02, 6.34875195e-03, 3.43805298e+02, 1.36100426e+01,\n",
       "       1.93226547e+01, 1.58448677e+01, 7.70502724e-03, 9.15346985e+01,\n",
       "       1.14448578e+05, 3.52834607e-03, 2.75567365e+00, 1.17304497e+01,\n",
       "       1.48266368e-03, 2.89147258e-01, 5.68299554e-04, 4.93045431e-03,\n",
       "       2.28469297e-01, 2.52308350e+03, 4.97026235e-01, 5.21769805e-04,\n",
       "       1.78885918e+01, 4.48642895e-02, 2.22660351e+00, 6.09555969e+01,\n",
       "       4.14110400e+03, 2.98636779e-02, 4.19222098e-03, 2.78468989e-02,\n",
       "       1.59133658e-01, 9.68337990e-04, 8.46709758e-02, 8.22756500e+01,\n",
       "       2.64177026e+03, 1.99175854e+01, 1.87944492e+04, 3.95200308e-03,\n",
       "       1.72476619e-01, 2.43936920e+01, 9.70419159e+01, 3.49700820e+04,\n",
       "       2.14441991e+00, 9.36335768e-04, 2.18864929e+02, 1.75355493e+03,\n",
       "       7.63366103e-01, 8.12852266e+04, 3.20924260e-02, 4.60273781e+01,\n",
       "       1.97975678e-04, 1.47313043e-01, 3.50101438e+05, 1.45483565e+00,\n",
       "       2.41621645e-04, 5.49038594e+04, 2.56255299e-01, 6.89069867e-01,\n",
       "       5.34925156e+01, 7.55751572e+01, 5.84564246e-02, 1.04631012e+02,\n",
       "       1.36483843e-02, 1.28305939e+02, 7.13396892e-02, 8.63026660e+03,\n",
       "       1.88244705e-03, 5.77745013e-05, 1.81255188e+01, 2.73864483e-03,\n",
       "       4.03897476e+00, 3.28580284e+01, 3.26681567e+03, 1.27911828e+05,\n",
       "       1.17236395e+01, 1.10250731e+01, 9.67747437e+02, 3.00590724e-01,\n",
       "       7.90875673e+00, 1.99176010e+02, 3.49641591e-03, 1.44786562e-03,\n",
       "       4.80845481e-01, 1.52908707e+00, 6.61723018e-01, 1.03622871e+02,\n",
       "       4.69131805e-02, 1.96429157e+01, 6.19592139e+03, 3.11392578e+02,\n",
       "       1.63364899e-03, 6.50353953e-02, 1.64757347e+01, 1.98348370e+01,\n",
       "       3.47853661e+01, 1.12790199e+02, 1.14389257e+01, 1.75990799e+02,\n",
       "       2.47941589e+01, 9.33149457e-01, 2.51335025e-01, 9.26087573e-02,\n",
       "       1.54499426e-01, 1.24713944e-04, 3.18637904e-05, 2.97453022e-03,\n",
       "       2.20745897e+00, 5.99729187e+02, 1.80331497e+01, 9.84860491e-03,\n",
       "       1.87279675e+03, 1.48211117e+01, 2.76862068e+01, 6.15375671e+01,\n",
       "       4.02810387e-02, 9.63904202e-01, 2.18301793e-07, 2.96236249e-04,\n",
       "       1.63338229e-01, 4.05162354e+01, 3.10909698e+02, 5.25068617e+00,\n",
       "       1.64122612e-03, 2.66326324e+02, 1.80933028e-04, 1.79243729e+02,\n",
       "       1.42000378e+03, 1.03231017e-02, 4.04450111e+01, 9.86463390e-03,\n",
       "       5.33631554e+01, 1.13536450e+03, 8.08336411e+01, 2.77220667e-03,\n",
       "       5.34808517e-01, 1.28794283e-01, 3.74290685e-04, 1.64414270e+03,\n",
       "       2.88717270e+00, 2.02816129e+00, 3.29676509e+00, 1.30905743e+01,\n",
       "       3.71037126e-02, 1.67867470e+01, 2.00864379e-04, 2.08104523e+02,\n",
       "       6.01152442e-02, 1.28960526e-02, 1.18840164e+02, 9.41599831e-02,\n",
       "       4.71061563e+00, 1.66855164e+02, 7.08858582e+02, 2.45956254e+00,\n",
       "       9.70797272e+01, 1.36139303e-01, 6.23822707e-05, 2.17118535e+04,\n",
       "       1.83867550e+00, 2.20875815e-03, 3.39781036e+02, 5.64395332e+01,\n",
       "       3.28891882e-04, 7.69075060e+00, 1.33980662e-04, 2.61582685e+00,\n",
       "       4.17145576e+01, 1.13635315e-02, 2.40798938e-04, 7.14155912e-01,\n",
       "       7.48962952e+02, 1.96876138e-01, 4.55716276e+00, 2.28920319e+02,\n",
       "       6.41985245e+01, 3.15003443e+00, 5.00157867e+02, 9.08197308e+00,\n",
       "       1.16178389e+04, 2.20473602e+02, 7.58044238e+03, 2.66970306e+02,\n",
       "       1.47347583e-03, 2.88604712e-03, 4.21788841e-01, 1.10891815e-02,\n",
       "       9.06641707e-02, 6.04564324e-03, 1.15911236e+01, 4.71302652e+00,\n",
       "       5.56702757e+00, 4.89125177e-02, 3.98855782e+01, 5.24335718e+00,\n",
       "       5.60284853e-01, 2.11158919e+00, 9.03953016e-01, 4.81266174e+01,\n",
       "       3.62805290e+01, 8.19571130e-03, 1.81776083e+00, 7.43096863e+02,\n",
       "       5.47808819e-02, 6.77371359e+00, 4.40478884e-02, 2.56776523e+04,\n",
       "       1.23162366e+03, 2.05730014e-02, 8.99595325e-04, 5.37998428e+01,\n",
       "       3.19071417e-03, 1.17835713e+04, 7.75512409e+00, 5.01157808e+00,\n",
       "       4.03700799e-01, 7.46399909e-03, 1.89277947e+00, 2.87635612e+00,\n",
       "       6.96781433e+02, 1.05904490e-01, 5.73232269e+01, 2.95600854e-02,\n",
       "       1.39037964e+03, 1.01606016e+01, 2.77323909e-02, 5.15577745e+00,\n",
       "       9.61776543e-03, 4.49301582e-03, 5.06144809e-03, 3.30137118e-06,\n",
       "       1.35097314e+03, 6.00385250e+05, 2.77470257e-02, 2.38250879e+03,\n",
       "       3.80702759e-03, 2.39998698e-01, 7.18315179e-03, 2.99669914e-02,\n",
       "       3.91865820e-02, 3.42604828e+01, 1.53817081e+00, 5.96588974e+01,\n",
       "       1.09815538e-01, 5.90636902e+01, 2.54459679e-02, 1.36774540e-01,\n",
       "       9.27160261e-04, 2.92882532e-01, 8.17922974e+00, 2.27454567e+01,\n",
       "       2.70867062e+00, 4.35907841e-01, 5.42137809e-02, 6.37478752e+01,\n",
       "       7.19447784e+01, 3.02040484e-04, 5.06583594e+03, 2.04034138e+00,\n",
       "       1.54465176e+04, 3.00205326e+00, 3.27520557e-02, 7.00242758e-01,\n",
       "       2.66394539e+01, 2.32354107e+01, 6.97616211e+02, 7.87739754e-01,\n",
       "       1.72620147e-01, 3.98229003e+00, 7.47519314e-01, 2.83958577e-03,\n",
       "       4.02462780e-02, 1.65571335e+02, 4.51243743e-02, 2.50829754e+01,\n",
       "       7.05498934e+00, 2.65700723e+04, 3.76153126e-04, 5.66430688e-01,\n",
       "       2.78091553e+03, 6.05295557e+03, 1.77885880e+02, 1.08318758e+00,\n",
       "       2.38299832e-01, 8.41953064e+02, 4.31090355e+00, 3.99810523e-02,\n",
       "       2.13711392e-05, 1.93335623e-01, 1.14365578e+01, 1.89275513e+01,\n",
       "       5.94138031e+01, 7.23198624e+01, 1.27663374e-01, 9.13847797e-03,\n",
       "       7.46831361e-08, 2.21902417e+03, 2.69977686e+03, 8.95047635e-02,\n",
       "       6.24612083e+01, 6.70667267e+00, 8.61103249e+00, 5.12155294e+00,\n",
       "       1.87749474e-03, 2.34054495e-02, 1.02286899e+00, 1.97670746e+01,\n",
       "       5.09815887e+02, 6.44055158e-02, 1.47241357e+03, 4.04010391e+01,\n",
       "       1.34340012e+02, 6.36776306e+02, 4.23740089e-01, 3.33290935e-01,\n",
       "       3.39101501e+02, 4.67249705e-03, 1.62385970e-01, 9.65725839e-01,\n",
       "       2.06725001e-02, 1.45897245e+00, 3.79880607e-01, 2.94704884e-01,\n",
       "       2.13226151e+00, 1.28332900e+04, 3.65444613e+00, 7.81058516e+04,\n",
       "       4.17830655e-03, 1.94781232e+00, 1.71119630e+00, 2.67298743e-02,\n",
       "       1.60338669e+01, 3.04274821e+00, 1.54289499e-01, 4.79834750e-02,\n",
       "       1.60698649e-02, 4.43078136e+00, 1.19466040e+03, 1.31376457e+01,\n",
       "       4.35040039e+02, 3.25383496e+00, 2.43245639e-04, 9.56776123e+01,\n",
       "       2.26247925e-02, 8.07459106e+01, 6.03254456e+02, 1.37320817e-01,\n",
       "       8.57579422e+01, 9.51502383e-01, 3.47547722e+00, 1.68129410e+02,\n",
       "       3.31425428e+00, 1.02321273e-02, 8.73388863e+00, 1.18088696e+03,\n",
       "       1.30549598e+00, 1.64410477e+02, 9.15589333e+00, 3.58633026e+02,\n",
       "       1.29122107e+03, 7.75484619e+01, 1.53293476e+01, 1.67915449e-02],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_distr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=860, shape=(1000,), dtype=float32, numpy=\n",
       "array([ 1.60564   ,  1.379874  ,  0.37944475,  0.23928322,  0.35129416,\n",
       "        0.5350127 ,  0.58887446,  3.7094767 ,  0.03705967,  0.6486339 ,\n",
       "        0.29919487,  3.3640707 ,  0.7692973 ,  0.153582  ,  0.92201734,\n",
       "        0.36696893,  8.129183  ,  0.6083264 ,  0.49984547,  5.672316  ,\n",
       "        0.20700514,  0.22036603,  0.12912177,  0.94990593,  0.82027286,\n",
       "        0.0970009 ,  3.2522144 ,  0.44362554,  0.9279015 ,  0.23899819,\n",
       "        6.7617755 ,  9.026428  ,  0.7018325 ,  0.28638062,  0.17627268,\n",
       "        0.74865276,  0.4431658 ,  0.22856337,  0.21052438,  0.15510939,\n",
       "        0.91958874,  0.3258133 ,  2.0351088 ,  0.12172444,  0.7549416 ,\n",
       "        0.3646252 ,  0.10030773,  0.71948314,  0.281849  ,  0.5646567 ,\n",
       "        0.4052561 ,  0.2630552 ,  0.7462153 ,  1.5540676 ,  1.2013553 ,\n",
       "        1.7074366 ,  1.826355  ,  0.15734006,  0.86663127,  0.48212838,\n",
       "        2.0446255 ,  0.11625703,  1.1176066 ,  2.1943846 ,  0.33802193,\n",
       "        0.1098136 ,  1.2314361 ,  0.22891906,  0.79357713,  0.59724927,\n",
       "        0.21597907,  2.3342457 ,  1.2109506 ,  0.10391884,  2.2203043 ,\n",
       "        2.6215997 ,  0.0716133 ,  1.1340995 ,  0.17135268,  1.4795722 ,\n",
       "        0.2792308 ,  0.8118575 ,  0.19234094,  0.39603657,  4.368979  ,\n",
       "        1.0258278 ,  0.2690934 ,  4.475712  ,  0.24232684,  0.6290017 ,\n",
       "        0.72567517,  0.6386955 ,  0.63365674,  1.2040144 ,  1.0064877 ,\n",
       "        9.879579  ,  1.7484186 ,  2.6837964 ,  0.73943657,  1.3147348 ,\n",
       "        1.7112875 ,  0.715038  ,  0.725324  ,  4.165575  ,  3.68968   ,\n",
       "        0.5045859 ,  0.3794855 ,  1.2152494 ,  0.82167655,  0.23258692,\n",
       "        0.5595465 ,  0.61512405,  5.981999  ,  1.784792  ,  0.30805543,\n",
       "        4.1736393 ,  0.4094196 ,  2.134065  ,  5.980787  ,  0.40509287,\n",
       "        0.1142813 ,  0.27587357,  2.3690653 ,  1.3368013 ,  0.72790384,\n",
       "        0.52944064,  0.996392  ,  0.14791092,  0.7620769 ,  0.07921672,\n",
       "        0.1944918 ,  0.17905892,  3.0045185 ,  2.2395566 ,  1.0042638 ,\n",
       "        0.5813687 ,  0.12065519,  0.59400976,  0.2081414 ,  0.43587795,\n",
       "        2.799296  ,  0.7259119 ,  0.04261545,  0.48140374,  1.9170871 ,\n",
       "        0.24209553,  0.6139847 ,  0.0705914 ,  0.5988428 ,  4.8421206 ,\n",
       "        0.6198638 ,  1.5386775 ,  0.14684689,  0.47347566,  2.9312038 ,\n",
       "        0.17159522,  1.3661557 ,  1.2050239 ,  0.38501108,  1.5644892 ,\n",
       "        0.5600335 ,  1.8508148 ,  1.2702752 ,  1.6033794 ,  1.7683522 ,\n",
       "        0.8997157 ,  0.3257723 ,  1.9670533 ,  0.28863126,  0.5488682 ,\n",
       "        0.05513405,  0.15648872,  2.8923354 ,  1.9479814 ,  0.07537563,\n",
       "        0.997396  ,  2.3958395 ,  1.1961772 ,  1.7977647 ,  0.2166232 ,\n",
       "        1.2441009 ,  2.837031  ,  1.0146625 ,  1.6016368 ,  1.5122678 ,\n",
       "        5.0713587 ,  2.2370622 ,  0.46337432,  0.4198648 ,  0.42193744,\n",
       "        1.8978747 ,  0.07910226,  0.99972856,  0.8895844 ,  0.49191788,\n",
       "        0.70417696,  0.1497102 ,  0.32739463,  1.1598613 ,  0.5264029 ,\n",
       "        0.460959  ,  0.33132443,  0.34781313,  1.6744744 ,  0.8437125 ,\n",
       "        0.16394106,  4.268996  ,  0.6886057 ,  0.5245538 ,  1.3788408 ,\n",
       "        0.1001393 ,  0.8932985 ,  0.0610179 ,  4.2861514 ,  0.601497  ,\n",
       "        0.471727  ,  0.5402848 ,  0.41725215,  1.5088863 ,  4.2568283 ,\n",
       "        1.9512091 ,  0.7466213 ,  0.14486992,  0.6927499 ,  0.55667937,\n",
       "        1.2129741 ,  0.42608172,  0.46349275,  2.6912906 ,  0.30755314,\n",
       "        2.822743  ,  0.75798917,  1.1930887 ,  1.4967899 ,  1.1757174 ,\n",
       "        0.28167   ,  1.4746405 ,  8.249268  ,  0.5170279 ,  3.0777698 ,\n",
       "        0.5599148 ,  1.4510453 ,  0.9777915 ,  0.17993404,  0.16105993,\n",
       "        1.8580642 ,  0.63149554,  3.934524  ,  0.16883549,  3.660953  ,\n",
       "        0.7149767 ,  0.5833538 ,  0.26084617,  1.8727126 ,  0.79191285,\n",
       "        0.42285663,  0.07005478,  1.4598906 ,  6.0517454 ,  0.4349788 ,\n",
       "        0.147771  ,  0.3006398 ,  0.82651526,  2.3365912 ,  0.2659124 ,\n",
       "        2.3006568 ,  0.43254352,  0.26358074,  0.54237795,  0.44879445,\n",
       "        1.5462779 ,  0.03570443,  0.41677326,  2.5216992 ,  0.61489356,\n",
       "        0.30282843,  0.6653076 ,  0.3045659 ,  0.42259052,  0.3408856 ,\n",
       "        0.13122015,  1.2069557 ,  0.18604411,  0.6524382 ,  0.6568624 ,\n",
       "        0.04011607,  0.63849515,  0.3063329 ,  0.6702641 ,  1.1863065 ,\n",
       "        2.116132  ,  0.35000822,  0.95868284,  0.9038995 ,  0.50049084,\n",
       "        3.8556874 ,  1.1179652 ,  1.347577  ,  0.09267735,  1.219497  ,\n",
       "        0.03565054,  1.9978658 ,  0.7670726 ,  0.46769524,  1.0639842 ,\n",
       "        0.14172359,  0.31932   ,  0.5487153 ,  0.53457695,  0.77855   ,\n",
       "        1.6165384 ,  0.2654099 ,  0.21181566,  0.11162372,  0.514073  ,\n",
       "        0.12664217,  0.54073507,  0.45072258,  0.335255  ,  0.23357342,\n",
       "        0.5085221 ,  1.4208659 ,  2.0896606 ,  1.4569153 ,  0.4449756 ,\n",
       "        4.4938855 ,  0.15608624,  0.700199  ,  0.32002577,  0.6874235 ,\n",
       "        0.15117106,  0.5412099 ,  2.7402532 ,  0.04517887,  0.6746264 ,\n",
       "        1.1683414 ,  0.35885054,  0.51460475,  1.267119  ,  3.387744  ,\n",
       "        0.5478625 ,  0.37533507,  0.47878036,  0.38481548,  1.7564436 ,\n",
       "        0.69414836,  1.3743106 ,  5.5514436 ,  0.6592398 ,  0.5391456 ,\n",
       "        0.546376  ,  0.48993272,  0.09249102,  2.7076926 ,  0.22058086,\n",
       "        2.031766  ,  0.25494397,  0.31018278,  0.56633794,  3.7054234 ,\n",
       "        0.6062141 ,  2.6058466 ,  0.71470076,  1.050146  ,  0.83159226,\n",
       "        0.3727031 ,  0.11618669,  1.3749074 ,  0.4246042 ,  0.6887123 ,\n",
       "        0.5465606 ,  0.93349886,  2.9114    ,  0.08631507,  0.5215996 ,\n",
       "        0.22246885,  0.3643264 ,  0.81655926,  0.9665547 ,  1.36327   ,\n",
       "        2.0980794 ,  0.24866824,  3.2930229 ,  1.0580132 ,  0.74756294,\n",
       "        0.37312225,  0.08007056,  0.76887363,  5.1105413 ,  0.9287756 ,\n",
       "        1.6827735 ,  0.05955742,  1.4896883 ,  0.6678614 ,  0.669334  ,\n",
       "        0.35597545,  0.6527979 ,  0.35577357,  0.54957   ,  0.68280125,\n",
       "        0.35595432,  1.817389  ,  0.2814937 ,  0.16457076,  1.6027621 ,\n",
       "        0.2828199 ,  1.0042845 ,  0.5504101 ,  0.7626441 ,  1.9922622 ,\n",
       "        0.1594396 ,  1.1624743 ,  0.63761973,  0.49014452,  0.41349566,\n",
       "        0.8809837 ,  1.4482874 ,  0.17424309,  0.5833613 ,  2.1634014 ,\n",
       "        0.29295427,  0.28678387,  2.2242408 ,  0.57732016,  0.35427755,\n",
       "        0.08549526,  1.0120586 ,  0.8313485 ,  0.08967873,  4.24959   ,\n",
       "        2.7597167 ,  0.16196793,  0.46848628,  0.93930763,  1.7785358 ,\n",
       "        4.131049  ,  0.3291038 ,  0.25863767,  1.2475688 ,  0.73943263,\n",
       "        0.19508854,  1.7016042 ,  1.0277416 ,  0.56716335,  1.7753366 ,\n",
       "        0.94951195,  0.15543035,  1.7153593 ,  0.03585248,  0.37484437,\n",
       "        0.28227133,  0.47397935,  0.1686043 ,  0.8396921 ,  5.1491733 ,\n",
       "        1.3396827 ,  0.04559417,  5.3356295 ,  0.85189706,  2.4070163 ,\n",
       "        2.047437  ,  0.2079992 ,  0.45107192,  0.28680187,  2.0276535 ,\n",
       "        0.40767673,  3.4999194 ,  2.066976  ,  0.55965084,  0.54407406,\n",
       "        0.32445192,  2.4055984 ,  0.3067002 ,  0.21747358,  1.8447745 ,\n",
       "        0.20961379,  2.4483159 ,  1.3668756 ,  0.08916125,  0.3807272 ,\n",
       "        2.4220016 ,  3.687047  ,  0.05719804,  0.18118294,  0.18030667,\n",
       "        0.6027728 ,  2.1043508 ,  0.6634054 ,  0.095202  ,  0.8921975 ,\n",
       "        0.34470105,  0.15613668,  0.3790275 ,  0.11543473,  0.59950674,\n",
       "        0.08544561,  0.28410605,  0.6353198 ,  1.5567392 ,  0.5890876 ,\n",
       "        0.52213424,  0.64227897,  0.36257008,  5.9938416 ,  0.13908568,\n",
       "        0.06169717,  1.1131854 ,  1.1914208 ,  5.010287  ,  3.161468  ,\n",
       "        0.18448195,  2.9572375 ,  0.2084117 ,  0.489184  ,  1.1985394 ,\n",
       "        0.11797513,  0.2336554 ,  0.9396312 ,  1.1482568 ,  0.29952073,\n",
       "        4.6484466 ,  1.1867971 ,  0.9085302 ,  0.21341   ,  1.3598017 ,\n",
       "        2.7930834 ,  0.5548514 ,  0.25145158,  0.97627336,  0.8353163 ,\n",
       "        1.0770577 ,  0.30750197,  4.0952387 ,  0.5900421 ,  0.10456154,\n",
       "        0.7775794 ,  1.1346576 ,  0.13441691,  0.54312253,  0.3226796 ,\n",
       "        3.4566    ,  1.553376  ,  4.535555  ,  0.28425446,  0.8828787 ,\n",
       "        0.9174301 ,  0.250902  ,  0.22805871,  1.8396862 ,  0.26197213,\n",
       "        0.6592854 ,  0.23611915,  0.07718888,  5.8603797 ,  0.9058724 ,\n",
       "        0.19110388,  1.2862082 ,  0.06244044,  3.4458208 ,  0.34670457,\n",
       "        1.1503631 ,  0.65323997,  0.539057  ,  0.3475479 ,  5.2299633 ,\n",
       "        1.735936  ,  1.0542023 ,  0.85425586,  0.8844255 ,  0.6903991 ,\n",
       "        0.57037044,  1.8187083 ,  1.377852  ,  0.5225341 ,  0.21224777,\n",
       "        0.23417473,  2.0536902 ,  1.08422   ,  2.3106828 ,  0.16819955,\n",
       "        0.41409764,  0.11435737,  0.33504462,  1.2072955 ,  0.2612684 ,\n",
       "        0.3045459 ,  2.2499862 ,  0.22187628,  6.6720695 ,  0.41944885,\n",
       "        0.9337219 ,  0.17617182,  0.50549227,  0.09863699,  0.20458725,\n",
       "        0.85695815,  6.6916046 ,  1.8339052 ,  2.873028  ,  0.63035524,\n",
       "        1.8347281 ,  1.2052073 ,  0.9939265 ,  0.3172666 ,  0.13811062,\n",
       "        0.19725032,  0.3590289 ,  0.90888417,  0.54076874,  0.8286764 ,\n",
       "        0.63665646,  0.19868371,  0.14397179,  3.3024945 ,  0.33964005,\n",
       "        0.49909294,  8.692146  ,  0.39949563,  0.57053715,  1.6757565 ,\n",
       "        0.5718262 ,  1.1301646 ,  0.4601204 ,  0.34133875,  0.42934301,\n",
       "        1.2063638 ,  0.33746484,  2.2905302 ,  1.0797771 ,  1.9653536 ,\n",
       "        0.44393992,  0.0778678 ,  0.11541486,  1.01898   ,  0.66811883,\n",
       "        1.0136762 ,  0.59590465,  1.2587225 ,  0.3699703 ,  0.6775588 ,\n",
       "        1.1556606 ,  0.16527463,  0.09713333,  0.12723354,  0.5102981 ,\n",
       "        1.1055329 ,  0.32438314,  0.5876622 ,  0.9753206 ,  0.70873934,\n",
       "        0.23600118,  0.88907117,  0.55404156,  0.28096938,  1.8302658 ,\n",
       "        0.04726988,  0.34571034,  0.75606424,  0.11512095,  1.4148293 ,\n",
       "        7.392107  ,  0.9053529 ,  0.37861174,  0.8015574 ,  0.22087069,\n",
       "        1.2169884 ,  0.17060208,  1.9812126 ,  0.4806396 ,  1.9657674 ,\n",
       "        0.5929503 ,  0.18427004,  1.5278648 ,  0.7877266 ,  0.34887418,\n",
       "        0.48803353,  0.29208243,  0.9460347 ,  0.5335824 ,  0.6397874 ,\n",
       "        0.66885895,  1.3024522 ,  0.24682184,  1.718662  ,  0.84433365,\n",
       "        0.50843513,  0.3710643 ,  0.08029473,  0.07637225,  0.46341395,\n",
       "        0.1336745 ,  1.9121022 ,  0.5851984 ,  1.9743667 ,  0.85771656,\n",
       "        0.34437844,  0.14286979,  0.44768444,  0.1438492 ,  0.6154559 ,\n",
       "        0.03717288,  0.36053157,  1.465187  ,  0.94826335,  0.561194  ,\n",
       "        0.42578432,  0.5352554 ,  0.6394028 ,  2.7273283 ,  0.36068666,\n",
       "        0.06340552, 12.995146  ,  0.50214875,  0.6297125 ,  3.1290193 ,\n",
       "        0.82354486,  0.5805187 ,  2.4572186 ,  2.0022666 ,  1.8646041 ,\n",
       "        0.38850838,  0.5237401 ,  0.06709492,  0.65136427,  0.5694163 ,\n",
       "        0.4846352 ,  0.5147484 ,  0.7110914 ,  0.9248592 ,  0.8536892 ,\n",
       "        0.08395066,  0.610649  ,  0.22276272,  0.39859155,  0.59812796,\n",
       "        1.7906789 ,  0.88061976,  3.118121  ,  0.53237617,  0.36749065,\n",
       "        0.72519577,  0.6392263 ,  0.16998367,  0.09119228,  0.23029333,\n",
       "        0.2237065 ,  0.38094229,  0.6204293 ,  0.91344327,  1.2402053 ,\n",
       "        2.7828817 ,  1.5764519 ,  0.44496316,  2.8282058 ,  0.2643178 ,\n",
       "        1.1550212 ,  1.3393269 ,  4.8677073 ,  3.6042104 ,  1.6851037 ,\n",
       "        0.6783229 ,  1.7191952 ,  0.5760171 ,  1.7184942 ,  0.60697275,\n",
       "        0.27161866,  1.6096395 ,  1.0483875 ,  0.2696736 ,  0.06559286,\n",
       "        1.3550968 ,  0.19919926,  3.0263162 ,  8.043699  ,  0.8051005 ,\n",
       "        0.38472208,  0.14593232,  0.50516635,  1.0802929 ,  1.8551575 ,\n",
       "        0.43896276,  0.53307074,  0.9023835 ,  0.68473566,  0.29308948,\n",
       "        0.41338715,  3.5932198 ,  0.41059035,  1.2457978 ,  0.522347  ,\n",
       "        0.8490651 ,  0.03816124,  0.7389655 ,  0.11751554,  0.74831825,\n",
       "        0.44107056,  7.7782273 ,  0.190942  ,  0.23076104,  0.4638379 ,\n",
       "        0.8766272 ,  0.47456238,  3.0967886 ,  3.3927474 ,  0.76894754,\n",
       "        0.08551959,  0.45963258,  0.5975296 ,  0.7503231 ,  0.08156603,\n",
       "        0.36529377,  0.41180542,  0.5896822 ,  0.6373241 ,  0.29575607,\n",
       "        2.3821023 ,  0.68104947,  0.54454094,  0.76412225,  0.05055184,\n",
       "        0.40412125,  1.3267523 ,  0.3687341 ,  0.23765554,  0.9255164 ,\n",
       "        2.413708  ,  0.16049594,  0.29473567,  2.0179024 ,  0.11439498,\n",
       "        0.70759386,  0.829731  ,  1.0206487 ,  0.33305812,  0.45137173,\n",
       "        1.911586  ,  1.2439475 ,  1.5251786 ,  0.18500179,  0.1283076 ,\n",
       "        0.22812618,  0.33212328,  0.14205304,  0.20973754,  0.5176182 ,\n",
       "        0.12512654,  0.72570956,  0.48897386,  0.8122258 ,  0.57783765,\n",
       "        0.94256103,  0.30819577,  1.3965865 ,  0.91790456,  3.927067  ,\n",
       "        2.4046292 ,  3.222793  ,  0.0762459 ,  0.2775809 ,  2.2892823 ,\n",
       "        0.27769312,  1.0620446 ,  0.53314847,  1.8747094 ,  0.53355825,\n",
       "        0.45133418,  1.5696542 ,  0.92877966,  1.5168746 ,  0.1794195 ,\n",
       "       12.863752  ,  0.17237122,  1.6894646 ,  0.78814584,  0.18299817,\n",
       "        1.1011885 ,  3.2472253 ,  1.9656487 ,  0.87637657,  0.8342702 ,\n",
       "        2.462472  ,  0.2311791 ,  1.9388908 ,  1.5041895 ,  0.4556094 ,\n",
       "        0.3500197 ,  0.82611024,  0.46568236, 15.161491  ,  0.20051807,\n",
       "       16.884321  ,  0.10470218,  0.1969185 ,  0.78090423,  0.7883266 ,\n",
       "        0.5384603 ,  0.03611306,  1.9381617 ,  0.6719027 ,  1.6103146 ,\n",
       "        0.11058807,  0.63933754,  0.15045951,  1.6311755 ,  0.1871104 ,\n",
       "        0.5479338 ,  0.24990834,  1.2732633 ,  0.5636222 ,  0.20610334,\n",
       "        2.2280836 ,  0.06888372,  0.45414516,  0.1962598 ,  0.48743904,\n",
       "        0.36871842,  1.271803  ,  4.379019  ,  1.7276558 ,  1.8789129 ,\n",
       "        0.19367605,  0.58711165,  1.2385741 ,  0.25331852,  0.51389897,\n",
       "        0.8204862 ,  0.6694232 ,  0.23574206,  0.25974393,  0.17360975,\n",
       "        0.2389639 ,  0.69257486,  0.26289982,  0.888368  ,  0.3770717 ,\n",
       "        0.47137326,  0.16726375,  0.20464045,  0.13823323,  0.68355924,\n",
       "        0.8897706 ,  0.9048511 ,  1.4246023 ,  1.1976845 ,  0.12716782,\n",
       "        1.0793194 ,  0.32276428,  0.3879909 ,  0.2057315 ,  3.076431  ,\n",
       "        0.7395062 ,  0.23164283,  1.2889179 ,  0.23504257,  0.3883283 ,\n",
       "        0.73604405,  0.39933422,  1.651131  ,  0.2878394 ,  1.5604231 ,\n",
       "        0.89547163,  0.24421172,  6.619992  ,  0.6638365 ,  0.45727107,\n",
       "        3.092841  ,  3.6866608 ,  1.3049316 ,  2.490855  ,  0.07648016,\n",
       "        1.9914887 ,  0.6006157 ,  1.0150033 ,  3.171759  ,  0.46789402,\n",
       "        1.3899239 ,  0.32700744,  4.330906  ,  0.11057027,  4.3293633 ,\n",
       "        0.81937003,  0.6737405 ,  0.48388308,  2.588508  ,  0.25180855,\n",
       "        0.2890411 ,  0.49559942,  0.26163545,  0.21739239,  0.98775744,\n",
       "        0.26231784,  0.20141451,  0.17466035,  1.1424042 ,  2.9561832 ,\n",
       "        0.06405142,  0.45861232,  0.44797933,  1.684613  ,  0.17392012],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 28us/sample - loss: 1530.7618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2819.313861816406"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1000/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 28us/sample - loss: 1530.7618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2819.313861816406"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.NegativeBinomial 'distribution_lambda_3_NegativeBinomial' batch_shape=[100000] event_shape=[] dtype=float32>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=585, shape=(100000,), dtype=float32, numpy=\n",
       "array([0.36850506, 0.74067277, 0.66926724, ..., 0.9999394 , 0.32746673,\n",
       "       0.4854044 ], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_distr.probs_parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=559, shape=(100000,), dtype=float32, numpy=\n",
       "array([0.2757673 , 0.32079494, 1.5467578 , ..., 8.653196  , 1.9845582 ,\n",
       "       1.8261846 ], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_distr.total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=563, shape=(100000,), dtype=float32, numpy=\n",
       "array([-0.5386355 ,  1.0494682 ,  0.7048727 , ...,  9.711327  ,\n",
       "       -0.71966517, -0.05839898], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_distr.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=606, shape=(100000,), dtype=float32, numpy=\n",
       "array([0.00000e+00, 2.00000e+00, 1.00000e+00, ..., 1.17367e+05,\n",
       "       0.00000e+00, 0.00000e+00], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples\n",
      "Epoch 1/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 883854.5843\n",
      "Epoch 2/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 797599.4587\n",
      "Epoch 3/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 700272.2095\n",
      "Epoch 4/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 679113.4192\n",
      "Epoch 5/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 685398.0334\n",
      "Epoch 6/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 658011.5871\n",
      "Epoch 7/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 592241.0647\n",
      "Epoch 8/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 573169.2325\n",
      "Epoch 9/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 573972.2151\n",
      "Epoch 10/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 529426.2192\n",
      "Epoch 11/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 506566.3763\n",
      "Epoch 12/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 499757.6481\n",
      "Epoch 13/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 485930.8255\n",
      "Epoch 14/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 470000.8785\n",
      "Epoch 15/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 436545.3260\n",
      "Epoch 16/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 410792.5965\n",
      "Epoch 17/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 386462.1067\n",
      "Epoch 18/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 399540.0485\n",
      "Epoch 19/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 368824.2042\n",
      "Epoch 20/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 388655.8593\n",
      "Epoch 21/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 369297.4900\n",
      "Epoch 22/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 346353.1148\n",
      "Epoch 23/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 307271.4387\n",
      "Epoch 24/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 320426.2625\n",
      "Epoch 25/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 313340.1781\n",
      "Epoch 26/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 306950.8391\n",
      "Epoch 27/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 292348.1729\n",
      "Epoch 28/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 308413.9260\n",
      "Epoch 29/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 277630.3092\n",
      "Epoch 30/1000\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 280280.6575\n",
      "Epoch 31/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 271944.1827\n",
      "Epoch 32/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 293963.9248\n",
      "Epoch 33/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 230169.0985\n",
      "Epoch 34/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 242334.7441\n",
      "Epoch 35/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 223518.3437\n",
      "Epoch 36/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 248898.9975\n",
      "Epoch 37/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 207855.7988\n",
      "Epoch 38/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 242130.6480\n",
      "Epoch 39/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 217825.5412\n",
      "Epoch 40/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 221670.5851\n",
      "Epoch 41/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 209502.5208\n",
      "Epoch 42/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 191587.4333\n",
      "Epoch 43/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 198196.6218\n",
      "Epoch 44/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 192389.7174\n",
      "Epoch 45/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 186442.9339\n",
      "Epoch 46/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 154254.0456\n",
      "Epoch 47/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 177645.2959\n",
      "Epoch 48/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 188651.8827\n",
      "Epoch 49/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 158536.4732\n",
      "Epoch 50/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 153962.9751\n",
      "Epoch 51/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 195705.5998\n",
      "Epoch 52/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 168221.0165\n",
      "Epoch 53/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 175988.0831\n",
      "Epoch 54/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 158912.4270\n",
      "Epoch 55/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 146297.1046\n",
      "Epoch 56/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 159058.8867\n",
      "Epoch 57/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 145831.1879\n",
      "Epoch 58/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 143571.4255\n",
      "Epoch 59/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 129726.1077\n",
      "Epoch 60/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 134938.7987\n",
      "Epoch 61/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 129884.3572\n",
      "Epoch 62/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 148164.3639\n",
      "Epoch 63/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 120327.3308\n",
      "Epoch 64/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 120980.3730\n",
      "Epoch 65/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 114827.2786\n",
      "Epoch 66/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 115798.9942\n",
      "Epoch 67/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 126567.1731\n",
      "Epoch 68/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 99862.2906\n",
      "Epoch 69/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 94851.8058\n",
      "Epoch 70/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 100433.8177\n",
      "Epoch 71/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 111154.1611\n",
      "Epoch 72/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 102333.1820\n",
      "Epoch 73/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 105286.9137\n",
      "Epoch 74/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 93892.5674\n",
      "Epoch 75/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 97480.8111\n",
      "Epoch 76/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 89149.1921\n",
      "Epoch 77/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 79898.1046\n",
      "Epoch 78/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 93484.1023\n",
      "Epoch 79/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 102103.8233\n",
      "Epoch 80/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 73801.9558\n",
      "Epoch 81/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 94437.3377\n",
      "Epoch 82/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 96231.0159\n",
      "Epoch 83/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 79783.4575\n",
      "Epoch 84/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 83699.0148\n",
      "Epoch 85/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 79546.6386\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 14us/sample - loss: 78979.0719\n",
      "Epoch 87/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 72332.8899\n",
      "Epoch 88/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 67804.3402\n",
      "Epoch 89/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 85219.3225\n",
      "Epoch 90/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 74885.7351\n",
      "Epoch 91/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 62060.7935\n",
      "Epoch 92/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 66371.7472\n",
      "Epoch 93/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 62596.4001\n",
      "Epoch 94/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 66457.3843\n",
      "Epoch 95/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 73813.2194\n",
      "Epoch 96/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 69454.1585\n",
      "Epoch 97/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 71279.2152\n",
      "Epoch 98/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 58543.1910\n",
      "Epoch 99/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 59139.2156\n",
      "Epoch 100/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 62402.0590\n",
      "Epoch 101/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 63475.8635\n",
      "Epoch 102/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 54719.7867\n",
      "Epoch 103/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 55277.5331\n",
      "Epoch 104/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 51837.3502\n",
      "Epoch 105/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 55827.9292\n",
      "Epoch 106/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 49765.5526\n",
      "Epoch 107/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 50467.7732\n",
      "Epoch 108/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 52972.4838\n",
      "Epoch 109/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 72410.7498\n",
      "Epoch 110/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 50127.6138\n",
      "Epoch 111/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 45636.1452\n",
      "Epoch 112/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 43033.9549\n",
      "Epoch 113/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 43877.5019\n",
      "Epoch 114/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 41760.3465\n",
      "Epoch 115/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 56250.9475\n",
      "Epoch 116/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 64386.5200\n",
      "Epoch 117/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 47785.0521\n",
      "Epoch 118/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 51939.6822\n",
      "Epoch 119/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 48763.4485\n",
      "Epoch 120/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 41268.2207\n",
      "Epoch 121/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 37718.2817\n",
      "Epoch 122/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 41563.2861\n",
      "Epoch 123/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 49527.6921\n",
      "Epoch 124/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 38826.2912\n",
      "Epoch 125/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 39350.8487\n",
      "Epoch 126/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 37289.2970\n",
      "Epoch 127/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 37768.3552\n",
      "Epoch 128/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 33244.6960\n",
      "Epoch 129/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 34152.6190\n",
      "Epoch 130/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 31860.9447\n",
      "Epoch 131/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 30115.3238\n",
      "Epoch 132/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 37263.6533\n",
      "Epoch 133/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 41451.4286\n",
      "Epoch 134/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 30389.6419\n",
      "Epoch 135/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 33815.1362\n",
      "Epoch 136/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 34776.4587\n",
      "Epoch 137/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 29756.9904\n",
      "Epoch 138/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 27737.2636\n",
      "Epoch 139/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 37534.9295\n",
      "Epoch 140/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 29240.1530\n",
      "Epoch 141/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 27762.4541\n",
      "Epoch 142/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 27679.4474\n",
      "Epoch 143/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 27511.0801\n",
      "Epoch 144/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 26126.1751\n",
      "Epoch 145/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 26082.5253\n",
      "Epoch 146/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 34765.0074\n",
      "Epoch 147/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 29056.1449\n",
      "Epoch 148/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 23785.5328\n",
      "Epoch 149/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 27799.2022\n",
      "Epoch 150/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 35550.9668\n",
      "Epoch 151/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 20848.3213\n",
      "Epoch 152/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 26496.8031\n",
      "Epoch 153/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 25266.4457\n",
      "Epoch 154/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 26847.9294\n",
      "Epoch 155/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 24060.9557\n",
      "Epoch 156/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 21723.4302\n",
      "Epoch 157/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 19177.6899\n",
      "Epoch 158/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 22437.4534\n",
      "Epoch 159/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 20275.3569\n",
      "Epoch 160/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 22016.8978\n",
      "Epoch 161/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 20576.2790\n",
      "Epoch 162/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 18626.4636\n",
      "Epoch 163/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 18134.4391\n",
      "Epoch 164/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 19963.7394\n",
      "Epoch 165/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 17511.3876\n",
      "Epoch 166/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 17521.7815\n",
      "Epoch 167/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 18612.4166\n",
      "Epoch 168/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 17330.2380\n",
      "Epoch 169/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 17447.6736\n",
      "Epoch 170/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 16201.3126\n",
      "Epoch 171/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 14us/sample - loss: 17670.2709\n",
      "Epoch 172/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 17398.8175\n",
      "Epoch 173/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 20154.2511\n",
      "Epoch 174/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 16641.1697\n",
      "Epoch 175/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 17300.9572\n",
      "Epoch 176/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 15770.5489\n",
      "Epoch 177/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 14618.0641\n",
      "Epoch 178/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 14553.3907\n",
      "Epoch 179/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 15954.1316\n",
      "Epoch 180/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 13630.1539\n",
      "Epoch 181/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13491.3494\n",
      "Epoch 182/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 15309.9614\n",
      "Epoch 183/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13555.3646\n",
      "Epoch 184/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11455.1493\n",
      "Epoch 185/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 13898.5392\n",
      "Epoch 186/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 16511.2411\n",
      "Epoch 187/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12593.8570\n",
      "Epoch 188/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11610.1164\n",
      "Epoch 189/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11867.2143\n",
      "Epoch 190/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12471.4907\n",
      "Epoch 191/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11485.0952\n",
      "Epoch 192/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13746.3566\n",
      "Epoch 193/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 10034.7482\n",
      "Epoch 194/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 9700.8549\n",
      "Epoch 195/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11094.2215\n",
      "Epoch 196/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 10710.2382\n",
      "Epoch 197/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 10488.3313\n",
      "Epoch 198/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 10459.3227\n",
      "Epoch 199/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 8816.7886\n",
      "Epoch 200/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 18265.7200\n",
      "Epoch 201/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 10367.2356\n",
      "Epoch 202/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 10776.5787\n",
      "Epoch 203/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 8788.8093\n",
      "Epoch 204/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 8085.7642\n",
      "Epoch 205/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 8236.5394\n",
      "Epoch 206/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 8938.0002\n",
      "Epoch 207/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 8591.8064\n",
      "Epoch 208/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 7853.3277\n",
      "Epoch 209/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 7988.4066\n",
      "Epoch 210/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 10100.7780\n",
      "Epoch 211/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 9280.1416\n",
      "Epoch 212/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 7805.9456\n",
      "Epoch 213/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 7967.9753\n",
      "Epoch 214/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 7603.0472\n",
      "Epoch 215/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 7165.8064\n",
      "Epoch 216/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 6503.0464\n",
      "Epoch 217/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 6718.4646\n",
      "Epoch 218/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 7226.8276\n",
      "Epoch 219/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 6363.4698\n",
      "Epoch 220/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 7325.0562\n",
      "Epoch 221/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 8840.2307\n",
      "Epoch 222/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 6282.7983\n",
      "Epoch 223/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 6931.2583\n",
      "Epoch 224/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 5810.4829\n",
      "Epoch 225/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 6507.4429\n",
      "Epoch 226/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 6101.7856\n",
      "Epoch 227/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 6511.6386\n",
      "Epoch 228/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 7256.3905\n",
      "Epoch 229/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 6761.2733\n",
      "Epoch 230/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 5372.5607\n",
      "Epoch 231/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 5283.2329\n",
      "Epoch 232/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 5628.0303\n",
      "Epoch 233/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 5245.0460\n",
      "Epoch 234/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 5579.3819\n",
      "Epoch 235/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 4665.3914\n",
      "Epoch 236/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 4410.2574\n",
      "Epoch 237/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 5388.8562\n",
      "Epoch 238/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 4434.3855\n",
      "Epoch 239/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 5065.6042\n",
      "Epoch 240/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 4357.0854\n",
      "Epoch 241/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 4878.5213\n",
      "Epoch 242/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 5014.7653\n",
      "Epoch 243/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 4508.3276\n",
      "Epoch 244/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 4645.6628\n",
      "Epoch 245/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 4505.2806\n",
      "Epoch 246/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 4117.2794\n",
      "Epoch 247/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 4386.6194\n",
      "Epoch 248/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 4239.7806\n",
      "Epoch 249/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 4123.0548\n",
      "Epoch 250/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 4179.2615\n",
      "Epoch 251/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 4044.3912\n",
      "Epoch 252/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 4215.6085\n",
      "Epoch 253/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 4112.1151\n",
      "Epoch 254/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 3637.9743\n",
      "Epoch 255/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 3355.2955\n",
      "Epoch 256/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 3732.0223\n",
      "Epoch 257/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 15us/sample - loss: 3149.0132\n",
      "Epoch 258/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 3852.9227\n",
      "Epoch 259/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 2923.3748\n",
      "Epoch 260/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 3217.9295\n",
      "Epoch 261/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 3901.5029\n",
      "Epoch 262/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 3037.5381\n",
      "Epoch 263/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 3023.1992\n",
      "Epoch 264/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 3086.9910\n",
      "Epoch 265/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 2676.1872\n",
      "Epoch 266/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 2586.8049\n",
      "Epoch 267/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 2967.9410\n",
      "Epoch 268/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 3010.8108\n",
      "Epoch 269/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 3466.0506\n",
      "Epoch 270/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 2683.6792\n",
      "Epoch 271/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 3153.8008\n",
      "Epoch 272/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 2866.5913\n",
      "Epoch 273/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 3283.7010\n",
      "Epoch 274/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 2673.9921\n",
      "Epoch 275/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 2308.5608\n",
      "Epoch 276/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 4242.5720\n",
      "Epoch 277/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 4422.7712\n",
      "Epoch 278/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 2265.3114\n",
      "Epoch 279/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 2087.2442\n",
      "Epoch 280/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 2027.2670\n",
      "Epoch 281/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 2178.9456\n",
      "Epoch 282/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1940.2054\n",
      "Epoch 283/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 2032.8515\n",
      "Epoch 284/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 2283.9384\n",
      "Epoch 285/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 2169.7580\n",
      "Epoch 286/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 2063.0678\n",
      "Epoch 287/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 2044.1728\n",
      "Epoch 288/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1942.5483\n",
      "Epoch 289/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 1811.2181\n",
      "Epoch 290/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 1768.0866\n",
      "Epoch 291/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 2092.2670\n",
      "Epoch 292/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 2033.5370\n",
      "Epoch 293/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1612.5723\n",
      "Epoch 294/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 1683.4299\n",
      "Epoch 295/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 1795.5826\n",
      "Epoch 296/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 1693.9893\n",
      "Epoch 297/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 1964.9741\n",
      "Epoch 298/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1997.2312\n",
      "Epoch 299/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1666.6944\n",
      "Epoch 300/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 1616.7351\n",
      "Epoch 301/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1846.7861\n",
      "Epoch 302/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 1586.0054\n",
      "Epoch 303/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1463.9180\n",
      "Epoch 304/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1493.0287\n",
      "Epoch 305/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 1455.1732\n",
      "Epoch 306/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1413.0639\n",
      "Epoch 307/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 1559.6586\n",
      "Epoch 308/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1448.2435\n",
      "Epoch 309/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 1323.7074\n",
      "Epoch 310/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1367.9687\n",
      "Epoch 311/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1409.9295\n",
      "Epoch 312/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1468.0605\n",
      "Epoch 313/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1438.6589\n",
      "Epoch 314/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 1131.0649\n",
      "Epoch 315/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1293.7843\n",
      "Epoch 316/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 1438.4636\n",
      "Epoch 317/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1135.2991\n",
      "Epoch 318/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1348.5895\n",
      "Epoch 319/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1117.4801\n",
      "Epoch 320/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1449.5124\n",
      "Epoch 321/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1243.4441\n",
      "Epoch 322/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 1173.4372\n",
      "Epoch 323/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 1103.8552\n",
      "Epoch 324/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 998.5349\n",
      "Epoch 325/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 947.2585\n",
      "Epoch 326/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 995.6905\n",
      "Epoch 327/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 945.9422\n",
      "Epoch 328/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1083.6165\n",
      "Epoch 329/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 1133.9025\n",
      "Epoch 330/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1062.0225\n",
      "Epoch 331/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1013.6940\n",
      "Epoch 332/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 804.3213\n",
      "Epoch 333/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 1015.4791\n",
      "Epoch 334/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 902.2595\n",
      "Epoch 335/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 975.4240\n",
      "Epoch 336/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 807.4322\n",
      "Epoch 337/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 893.6300\n",
      "Epoch 338/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 1005.9543\n",
      "Epoch 339/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 889.3139\n",
      "Epoch 340/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 692.9674\n",
      "Epoch 341/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 761.7796\n",
      "Epoch 342/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 808.3132\n",
      "Epoch 343/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 15us/sample - loss: 975.2159\n",
      "Epoch 344/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 803.2547\n",
      "Epoch 345/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 722.6273\n",
      "Epoch 346/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 723.3779\n",
      "Epoch 347/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 747.4705\n",
      "Epoch 348/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 797.9753\n",
      "Epoch 349/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 751.8869\n",
      "Epoch 350/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 605.0789\n",
      "Epoch 351/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 786.1795\n",
      "Epoch 352/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 669.3014\n",
      "Epoch 353/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 690.5146\n",
      "Epoch 354/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 608.3170\n",
      "Epoch 355/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 575.1111\n",
      "Epoch 356/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 494.0131\n",
      "Epoch 357/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 685.1855\n",
      "Epoch 358/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 591.5696\n",
      "Epoch 359/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 680.4504\n",
      "Epoch 360/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 613.1809\n",
      "Epoch 361/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 559.1919\n",
      "Epoch 362/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 599.7350\n",
      "Epoch 363/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 568.2289\n",
      "Epoch 364/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 630.5804\n",
      "Epoch 365/1000\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 506.1867\n",
      "Epoch 366/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 511.3123\n",
      "Epoch 367/1000\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 478.9306\n",
      "Epoch 368/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 497.6728\n",
      "Epoch 369/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 546.9590\n",
      "Epoch 370/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 594.6412\n",
      "Epoch 371/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 464.4237\n",
      "Epoch 372/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 494.7021\n",
      "Epoch 373/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 449.9985\n",
      "Epoch 374/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 440.3330\n",
      "Epoch 375/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 461.4503\n",
      "Epoch 376/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 466.8026\n",
      "Epoch 377/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 406.6950\n",
      "Epoch 378/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 438.9374\n",
      "Epoch 379/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 362.9372\n",
      "Epoch 380/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 479.3318\n",
      "Epoch 381/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 350.0260\n",
      "Epoch 382/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 408.1383\n",
      "Epoch 383/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 343.2557\n",
      "Epoch 384/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 364.6511\n",
      "Epoch 385/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 384.7872\n",
      "Epoch 386/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 390.0846\n",
      "Epoch 387/1000\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 462.5893\n",
      "Epoch 388/1000\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 375.3197\n",
      "Epoch 389/1000\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 346.5314\n",
      "Epoch 390/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 296.6929\n",
      "Epoch 391/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 343.0909\n",
      "Epoch 392/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 302.8089\n",
      "Epoch 393/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 333.0570\n",
      "Epoch 394/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 282.6581\n",
      "Epoch 395/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 266.0748\n",
      "Epoch 396/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 303.2292\n",
      "Epoch 397/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 276.1440\n",
      "Epoch 398/1000\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 290.6330\n",
      "Epoch 399/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 289.8157\n",
      "Epoch 400/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 323.3303\n",
      "Epoch 401/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 248.2199\n",
      "Epoch 402/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 348.4857\n",
      "Epoch 403/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 302.9381\n",
      "Epoch 404/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 437.5388\n",
      "Epoch 405/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 289.7213\n",
      "Epoch 406/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 242.7196\n",
      "Epoch 407/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 294.5083\n",
      "Epoch 408/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 234.3029\n",
      "Epoch 409/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 271.4822\n",
      "Epoch 410/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 249.8905\n",
      "Epoch 411/1000\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 249.4591\n",
      "Epoch 412/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 226.6033\n",
      "Epoch 413/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 227.3252\n",
      "Epoch 414/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 222.8312\n",
      "Epoch 415/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 207.2383\n",
      "Epoch 416/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 192.8601\n",
      "Epoch 417/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 195.8559\n",
      "Epoch 418/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 205.7267\n",
      "Epoch 419/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 218.5567\n",
      "Epoch 420/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 256.9947\n",
      "Epoch 421/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 177.0838\n",
      "Epoch 422/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 185.7250\n",
      "Epoch 423/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 233.4466\n",
      "Epoch 424/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 185.3387\n",
      "Epoch 425/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 187.8792\n",
      "Epoch 426/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 183.7327\n",
      "Epoch 427/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 172.8181\n",
      "Epoch 428/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 180.6888\n",
      "Epoch 429/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 164.4905\n",
      "Epoch 430/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 15us/sample - loss: 179.5027\n",
      "Epoch 431/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 173.6640\n",
      "Epoch 432/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 151.0379\n",
      "Epoch 433/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 159.0301\n",
      "Epoch 434/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 183.1464\n",
      "Epoch 435/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 172.0546\n",
      "Epoch 436/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 163.3154\n",
      "Epoch 437/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 166.0617\n",
      "Epoch 438/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 171.0200\n",
      "Epoch 439/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 141.4174\n",
      "Epoch 440/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 153.0425\n",
      "Epoch 441/1000\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 146.5822\n",
      "Epoch 442/1000\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 166.4554\n",
      "Epoch 443/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 134.6750\n",
      "Epoch 444/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 136.6777\n",
      "Epoch 445/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 139.8187\n",
      "Epoch 446/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 120.5191\n",
      "Epoch 447/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 127.7975\n",
      "Epoch 448/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 134.3693\n",
      "Epoch 449/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 132.5412\n",
      "Epoch 450/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 138.6997\n",
      "Epoch 451/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 144.1217\n",
      "Epoch 452/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 128.4219\n",
      "Epoch 453/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 108.7727\n",
      "Epoch 454/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 111.5456\n",
      "Epoch 455/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 147.1634\n",
      "Epoch 456/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 122.0121\n",
      "Epoch 457/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 133.0085\n",
      "Epoch 458/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 104.9074\n",
      "Epoch 459/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 101.4458\n",
      "Epoch 460/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 94.9045\n",
      "Epoch 461/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 101.5471\n",
      "Epoch 462/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 103.1385\n",
      "Epoch 463/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 112.5173\n",
      "Epoch 464/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 122.7989\n",
      "Epoch 465/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 113.8486\n",
      "Epoch 466/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 97.5881\n",
      "Epoch 467/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 93.0358\n",
      "Epoch 468/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 94.5698\n",
      "Epoch 469/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 89.3092\n",
      "Epoch 470/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 85.5997\n",
      "Epoch 471/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 81.6250\n",
      "Epoch 472/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 83.5739\n",
      "Epoch 473/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 83.9261\n",
      "Epoch 474/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 89.6849\n",
      "Epoch 475/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 79.4115\n",
      "Epoch 476/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 81.2085\n",
      "Epoch 477/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 80.3259\n",
      "Epoch 478/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 74.0032\n",
      "Epoch 479/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 78.8850\n",
      "Epoch 480/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 78.4375\n",
      "Epoch 481/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 71.9821\n",
      "Epoch 482/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 81.2373\n",
      "Epoch 483/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 78.1270\n",
      "Epoch 484/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 97.4511\n",
      "Epoch 485/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 75.5177\n",
      "Epoch 486/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 62.4512\n",
      "Epoch 487/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 75.4361\n",
      "Epoch 488/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 72.4385\n",
      "Epoch 489/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 64.2552\n",
      "Epoch 490/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 70.4172\n",
      "Epoch 491/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 79.4599\n",
      "Epoch 492/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 72.1690\n",
      "Epoch 493/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 66.5207\n",
      "Epoch 494/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 73.8432\n",
      "Epoch 495/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 61.3747\n",
      "Epoch 496/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 60.7577\n",
      "Epoch 497/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 56.8230\n",
      "Epoch 498/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 70.1756\n",
      "Epoch 499/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 61.8105\n",
      "Epoch 500/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 62.6247\n",
      "Epoch 501/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 57.4137\n",
      "Epoch 502/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 61.5591\n",
      "Epoch 503/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 58.4863\n",
      "Epoch 504/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 54.2841\n",
      "Epoch 505/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 56.7358\n",
      "Epoch 506/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 51.2543\n",
      "Epoch 507/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 53.2967\n",
      "Epoch 508/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 50.4612\n",
      "Epoch 509/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 46.3751\n",
      "Epoch 510/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 48.2669\n",
      "Epoch 511/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 55.5012\n",
      "Epoch 512/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 63.1702\n",
      "Epoch 513/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 48.6361\n",
      "Epoch 514/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 43.7614\n",
      "Epoch 515/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 51.5555\n",
      "Epoch 516/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 42.3327\n",
      "Epoch 517/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 14us/sample - loss: 49.9012\n",
      "Epoch 518/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 49.1762\n",
      "Epoch 519/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 40.8963\n",
      "Epoch 520/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 39.9691\n",
      "Epoch 521/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 47.1436\n",
      "Epoch 522/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 44.0028\n",
      "Epoch 523/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 42.5585\n",
      "Epoch 524/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 44.0005\n",
      "Epoch 525/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 40.2239\n",
      "Epoch 526/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 40.1782\n",
      "Epoch 527/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 40.7697\n",
      "Epoch 528/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 37.3981\n",
      "Epoch 529/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 38.0797\n",
      "Epoch 530/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 39.4725\n",
      "Epoch 531/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 36.5324\n",
      "Epoch 532/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 33.8148\n",
      "Epoch 533/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 36.5018\n",
      "Epoch 534/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 34.8931\n",
      "Epoch 535/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 38.0560\n",
      "Epoch 536/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 37.6294\n",
      "Epoch 537/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 36.8839\n",
      "Epoch 538/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 36.9864\n",
      "Epoch 539/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 31.9404\n",
      "Epoch 540/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 30.6763\n",
      "Epoch 541/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 34.8283\n",
      "Epoch 542/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 31.8310\n",
      "Epoch 543/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 40.9448\n",
      "Epoch 544/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 30.5956\n",
      "Epoch 545/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 33.7506\n",
      "Epoch 546/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 31.0714\n",
      "Epoch 547/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 31.8702\n",
      "Epoch 548/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 28.5712\n",
      "Epoch 549/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 30.1202\n",
      "Epoch 550/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 31.2955\n",
      "Epoch 551/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 28.8622\n",
      "Epoch 552/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 29.8037\n",
      "Epoch 553/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 28.1502\n",
      "Epoch 554/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 31.3868\n",
      "Epoch 555/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 29.4308\n",
      "Epoch 556/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 29.6403\n",
      "Epoch 557/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 26.9308\n",
      "Epoch 558/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 29.7567\n",
      "Epoch 559/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 26.0409\n",
      "Epoch 560/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 28.1409\n",
      "Epoch 561/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 24.8276\n",
      "Epoch 562/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 26.1221\n",
      "Epoch 563/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 23.7136\n",
      "Epoch 564/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 25.6286\n",
      "Epoch 565/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 27.1758\n",
      "Epoch 566/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 23.5934\n",
      "Epoch 567/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 23.7220\n",
      "Epoch 568/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 23.1033\n",
      "Epoch 569/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 23.5915\n",
      "Epoch 570/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 24.2794\n",
      "Epoch 571/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 27.3728\n",
      "Epoch 572/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 25.8972\n",
      "Epoch 573/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 22.3531\n",
      "Epoch 574/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 24.5068\n",
      "Epoch 575/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 23.8698\n",
      "Epoch 576/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 23.8898\n",
      "Epoch 577/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 22.3834\n",
      "Epoch 578/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 22.2662\n",
      "Epoch 579/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 22.1279\n",
      "Epoch 580/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 24.0003\n",
      "Epoch 581/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 21.6695\n",
      "Epoch 582/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 21.0410\n",
      "Epoch 583/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 21.3127\n",
      "Epoch 584/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 22.8362\n",
      "Epoch 585/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 20.7498\n",
      "Epoch 586/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 22.3231\n",
      "Epoch 587/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 20.6389\n",
      "Epoch 588/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 21.2185\n",
      "Epoch 589/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 27.7905\n",
      "Epoch 590/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 20.0518\n",
      "Epoch 591/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 19.6194\n",
      "Epoch 592/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 19.4133\n",
      "Epoch 593/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 19.8290\n",
      "Epoch 594/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 18.7821\n",
      "Epoch 595/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 21.2422\n",
      "Epoch 596/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 19.4020\n",
      "Epoch 597/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 18.6998\n",
      "Epoch 598/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 21.9532\n",
      "Epoch 599/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 18.8982\n",
      "Epoch 600/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 17.1515\n",
      "Epoch 601/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 18.0993\n",
      "Epoch 602/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 19.7655\n",
      "Epoch 603/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 18.5955\n",
      "Epoch 604/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 18.1797\n",
      "Epoch 605/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 15us/sample - loss: 18.4248\n",
      "Epoch 606/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 16.6911\n",
      "Epoch 607/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 18.1171\n",
      "Epoch 608/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 18.6735\n",
      "Epoch 609/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 21.8857\n",
      "Epoch 610/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 17.5065\n",
      "Epoch 611/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 18.2606\n",
      "Epoch 612/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 17.4738\n",
      "Epoch 613/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 16.4658\n",
      "Epoch 614/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 17.2922\n",
      "Epoch 615/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 17.6818\n",
      "Epoch 616/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 16.7975\n",
      "Epoch 617/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 16.5617\n",
      "Epoch 618/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 16.1733\n",
      "Epoch 619/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 16.6750\n",
      "Epoch 620/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 15.6898\n",
      "Epoch 621/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 16.3002\n",
      "Epoch 622/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 16.7464\n",
      "Epoch 623/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 16.1878\n",
      "Epoch 624/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 16.0228\n",
      "Epoch 625/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 16.4676\n",
      "Epoch 626/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 16.5618\n",
      "Epoch 627/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 15.8706\n",
      "Epoch 628/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 15.1705\n",
      "Epoch 629/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 15.5004\n",
      "Epoch 630/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 16.1757\n",
      "Epoch 631/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 15.8162\n",
      "Epoch 632/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 14.9882\n",
      "Epoch 633/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 15.1801\n",
      "Epoch 634/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 15.9222\n",
      "Epoch 635/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 14.9983\n",
      "Epoch 636/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 14.9742\n",
      "Epoch 637/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 14.9766\n",
      "Epoch 638/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 14.8887\n",
      "Epoch 639/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 15.3930\n",
      "Epoch 640/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 15.2716\n",
      "Epoch 641/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 14.8936\n",
      "Epoch 642/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 15.3507\n",
      "Epoch 643/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 14.2885\n",
      "Epoch 644/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 14.6269\n",
      "Epoch 645/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 14.4891\n",
      "Epoch 646/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 14.2189\n",
      "Epoch 647/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 14.8920\n",
      "Epoch 648/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 14.3785\n",
      "Epoch 649/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 14.0619\n",
      "Epoch 650/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 14.4005\n",
      "Epoch 651/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 13.8868\n",
      "Epoch 652/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 14.5966\n",
      "Epoch 653/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 14.5897\n",
      "Epoch 654/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 14.1201\n",
      "Epoch 655/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 13.8333\n",
      "Epoch 656/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 13.8688\n",
      "Epoch 657/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13.6090\n",
      "Epoch 658/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 13.4585\n",
      "Epoch 659/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 14.0414\n",
      "Epoch 660/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 13.7408\n",
      "Epoch 661/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13.6464\n",
      "Epoch 662/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 13.4861\n",
      "Epoch 663/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13.2547\n",
      "Epoch 664/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13.4899\n",
      "Epoch 665/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 13.3478\n",
      "Epoch 666/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 13.3332\n",
      "Epoch 667/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13.2208\n",
      "Epoch 668/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13.2687\n",
      "Epoch 669/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13.7779\n",
      "Epoch 670/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13.0041\n",
      "Epoch 671/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.7632\n",
      "Epoch 672/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 13.1919\n",
      "Epoch 673/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.8495\n",
      "Epoch 674/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 13.4289\n",
      "Epoch 675/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.9641\n",
      "Epoch 676/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 13.0592\n",
      "Epoch 677/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.8268\n",
      "Epoch 678/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13.1117\n",
      "Epoch 679/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.8634\n",
      "Epoch 680/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.9324\n",
      "Epoch 681/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 12.9630\n",
      "Epoch 682/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12.8859\n",
      "Epoch 683/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12.5652\n",
      "Epoch 684/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.8497\n",
      "Epoch 685/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 12.6939\n",
      "Epoch 686/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.7687\n",
      "Epoch 687/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12.5766\n",
      "Epoch 688/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 12.5875\n",
      "Epoch 689/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.7025\n",
      "Epoch 690/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.7016\n",
      "Epoch 691/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 12.5305\n",
      "Epoch 692/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.2976\n",
      "Epoch 693/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12.3678\n",
      "Epoch 694/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.2775\n",
      "Epoch 695/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 12.3883\n",
      "Epoch 696/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 12.2945\n",
      "Epoch 697/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.2846\n",
      "Epoch 698/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12.2579\n",
      "Epoch 699/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12.4089\n",
      "Epoch 700/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.3997\n",
      "Epoch 701/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.2058\n",
      "Epoch 702/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 12.3158\n",
      "Epoch 703/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.2795\n",
      "Epoch 704/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.2334\n",
      "Epoch 705/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.1678\n",
      "Epoch 706/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.1802\n",
      "Epoch 707/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 13.0606\n",
      "Epoch 708/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12.0660\n",
      "Epoch 709/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.9979\n",
      "Epoch 710/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 12.0284\n",
      "Epoch 711/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.0081\n",
      "Epoch 712/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 12.0226\n",
      "Epoch 713/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.9702\n",
      "Epoch 714/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12.1008\n",
      "Epoch 715/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12.0807\n",
      "Epoch 716/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 12.1296\n",
      "Epoch 717/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 12.0049\n",
      "Epoch 718/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12.0098\n",
      "Epoch 719/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 12.1989\n",
      "Epoch 720/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.9893\n",
      "Epoch 721/1000\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 11.9092\n",
      "Epoch 722/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.8483\n",
      "Epoch 723/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.7564\n",
      "Epoch 724/1000\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 11.7826\n",
      "Epoch 725/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.8617\n",
      "Epoch 726/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.7489\n",
      "Epoch 727/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.8719\n",
      "Epoch 728/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.7651\n",
      "Epoch 729/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.7799\n",
      "Epoch 730/1000\n",
      "10000/10000 [==============================] - 0s 21us/sample - loss: 11.8966\n",
      "Epoch 731/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.8021\n",
      "Epoch 732/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.8312\n",
      "Epoch 733/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.7535\n",
      "Epoch 734/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.7897\n",
      "Epoch 735/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.6663\n",
      "Epoch 736/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.7238\n",
      "Epoch 737/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.6564\n",
      "Epoch 738/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.8242\n",
      "Epoch 739/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.6376\n",
      "Epoch 740/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.6174\n",
      "Epoch 741/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.6059\n",
      "Epoch 742/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.6307\n",
      "Epoch 743/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.6790\n",
      "Epoch 744/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.6668\n",
      "Epoch 745/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.6046\n",
      "Epoch 746/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.5796\n",
      "Epoch 747/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.5542\n",
      "Epoch 748/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.5987\n",
      "Epoch 749/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.6228\n",
      "Epoch 750/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.7126\n",
      "Epoch 751/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.5220\n",
      "Epoch 752/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.5284\n",
      "Epoch 753/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.5942\n",
      "Epoch 754/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.5602\n",
      "Epoch 755/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.4936\n",
      "Epoch 756/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.5186\n",
      "Epoch 757/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.5103\n",
      "Epoch 758/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.5060\n",
      "Epoch 759/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.4822\n",
      "Epoch 760/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.5318\n",
      "Epoch 761/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.4431\n",
      "Epoch 762/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 11.4837\n",
      "Epoch 763/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.4494\n",
      "Epoch 764/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.4585\n",
      "Epoch 765/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.4206\n",
      "Epoch 766/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.4927\n",
      "Epoch 767/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.4666\n",
      "Epoch 768/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.4334\n",
      "Epoch 769/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.4474\n",
      "Epoch 770/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.4184\n",
      "Epoch 771/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.4205\n",
      "Epoch 772/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3842\n",
      "Epoch 773/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.3822\n",
      "Epoch 774/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3843\n",
      "Epoch 775/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3786\n",
      "Epoch 776/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.3954\n",
      "Epoch 777/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.4271\n",
      "Epoch 778/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.4334\n",
      "Epoch 779/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.3496\n",
      "Epoch 780/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.3628\n",
      "Epoch 781/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.3733\n",
      "Epoch 782/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3541\n",
      "Epoch 783/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3564\n",
      "Epoch 784/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.3969\n",
      "Epoch 785/1000\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 11.3463\n",
      "Epoch 786/1000\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 11.3028\n",
      "Epoch 787/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.3622\n",
      "Epoch 788/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3336\n",
      "Epoch 789/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3042\n",
      "Epoch 790/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.3274\n",
      "Epoch 791/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.3327\n",
      "Epoch 792/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.2924\n",
      "Epoch 793/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.3423\n",
      "Epoch 794/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.3397\n",
      "Epoch 795/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3059\n",
      "Epoch 796/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2890\n",
      "Epoch 797/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2857\n",
      "Epoch 798/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3207\n",
      "Epoch 799/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3019\n",
      "Epoch 800/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.3105\n",
      "Epoch 801/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2969\n",
      "Epoch 802/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2748\n",
      "Epoch 803/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3002\n",
      "Epoch 804/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3143\n",
      "Epoch 805/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2783\n",
      "Epoch 806/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.3088\n",
      "Epoch 807/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2634\n",
      "Epoch 808/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2618\n",
      "Epoch 809/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2758\n",
      "Epoch 810/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.2659\n",
      "Epoch 811/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2642\n",
      "Epoch 812/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.3189\n",
      "Epoch 813/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.2783\n",
      "Epoch 814/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2421\n",
      "Epoch 815/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2505\n",
      "Epoch 816/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2448\n",
      "Epoch 817/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2469\n",
      "Epoch 818/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2347\n",
      "Epoch 819/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2417\n",
      "Epoch 820/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2176\n",
      "Epoch 821/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2469\n",
      "Epoch 822/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2330\n",
      "Epoch 823/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.2363\n",
      "Epoch 824/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2442\n",
      "Epoch 825/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2304\n",
      "Epoch 826/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2312\n",
      "Epoch 827/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2216\n",
      "Epoch 828/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2096\n",
      "Epoch 829/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.2606\n",
      "Epoch 830/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 11.2157\n",
      "Epoch 831/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 11.2242\n",
      "Epoch 832/1000\n",
      "10000/10000 [==============================] - 0s 12us/sample - loss: 11.2156\n",
      "Epoch 833/1000\n",
      "10000/10000 [==============================] - 0s 13us/sample - loss: 11.2064\n",
      "Epoch 834/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2061\n",
      "Epoch 835/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2390\n",
      "Epoch 836/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2108\n",
      "Epoch 837/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.2045\n",
      "Epoch 838/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1981\n",
      "Epoch 839/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2068\n",
      "Epoch 840/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2148\n",
      "Epoch 841/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1937\n",
      "Epoch 842/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1958\n",
      "Epoch 843/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1877\n",
      "Epoch 844/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1937\n",
      "Epoch 845/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2056\n",
      "Epoch 846/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1954\n",
      "Epoch 847/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2025\n",
      "Epoch 848/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2006\n",
      "Epoch 849/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.2082\n",
      "Epoch 850/1000\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 11.2121\n",
      "Epoch 851/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.2046\n",
      "Epoch 852/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1963\n",
      "Epoch 853/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1850\n",
      "Epoch 854/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1731\n",
      "Epoch 855/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1747\n",
      "Epoch 856/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1922\n",
      "Epoch 857/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1892\n",
      "Epoch 858/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1735\n",
      "Epoch 859/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1815\n",
      "Epoch 860/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1868\n",
      "Epoch 861/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1754\n",
      "Epoch 862/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1717\n",
      "Epoch 863/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1779\n",
      "Epoch 864/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1916\n",
      "Epoch 865/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1752\n",
      "Epoch 866/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1815\n",
      "Epoch 867/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1703\n",
      "Epoch 868/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1762\n",
      "Epoch 869/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1683\n",
      "Epoch 870/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1788\n",
      "Epoch 871/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1714\n",
      "Epoch 872/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1714\n",
      "Epoch 873/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1742\n",
      "Epoch 874/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1645\n",
      "Epoch 875/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1657\n",
      "Epoch 876/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1644\n",
      "Epoch 877/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1687\n",
      "Epoch 878/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1750\n",
      "Epoch 879/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1665\n",
      "Epoch 880/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1628\n",
      "Epoch 881/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1607\n",
      "Epoch 882/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1608\n",
      "Epoch 883/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1629\n",
      "Epoch 884/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1577\n",
      "Epoch 885/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1581\n",
      "Epoch 886/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1574\n",
      "Epoch 887/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1614\n",
      "Epoch 888/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1584\n",
      "Epoch 889/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1551\n",
      "Epoch 890/1000\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 11.1627\n",
      "Epoch 891/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1642\n",
      "Epoch 892/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1619\n",
      "Epoch 893/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1619\n",
      "Epoch 894/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1611\n",
      "Epoch 895/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1611\n",
      "Epoch 896/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1617\n",
      "Epoch 897/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1550\n",
      "Epoch 898/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1536\n",
      "Epoch 899/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1593\n",
      "Epoch 900/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1480\n",
      "Epoch 901/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1626\n",
      "Epoch 902/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1542\n",
      "Epoch 903/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1556\n",
      "Epoch 904/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1600\n",
      "Epoch 905/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1605\n",
      "Epoch 906/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1556\n",
      "Epoch 907/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1501\n",
      "Epoch 908/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1495\n",
      "Epoch 909/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1528\n",
      "Epoch 910/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1539\n",
      "Epoch 911/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1571\n",
      "Epoch 912/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1592\n",
      "Epoch 913/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1511\n",
      "Epoch 914/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1508\n",
      "Epoch 915/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1515\n",
      "Epoch 916/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1510\n",
      "Epoch 917/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1490\n",
      "Epoch 918/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1531\n",
      "Epoch 919/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1521\n",
      "Epoch 920/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1533\n",
      "Epoch 921/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1469\n",
      "Epoch 922/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1445\n",
      "Epoch 923/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1482\n",
      "Epoch 924/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1530\n",
      "Epoch 925/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1499\n",
      "Epoch 926/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1436\n",
      "Epoch 927/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1452\n",
      "Epoch 928/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1440\n",
      "Epoch 929/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1421\n",
      "Epoch 930/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1436\n",
      "Epoch 931/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1468\n",
      "Epoch 932/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1479\n",
      "Epoch 933/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1493\n",
      "Epoch 934/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1435\n",
      "Epoch 935/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1481\n",
      "Epoch 936/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1451\n",
      "Epoch 937/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1440\n",
      "Epoch 938/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1446\n",
      "Epoch 939/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1506\n",
      "Epoch 940/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1426\n",
      "Epoch 941/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1451\n",
      "Epoch 942/1000\n",
      "10000/10000 [==============================] - 0s 18us/sample - loss: 11.1442\n",
      "Epoch 943/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1427\n",
      "Epoch 944/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1451\n",
      "Epoch 945/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1439\n",
      "Epoch 946/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1415\n",
      "Epoch 947/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1411\n",
      "Epoch 948/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1432\n",
      "Epoch 949/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1466\n",
      "Epoch 950/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1455\n",
      "Epoch 951/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1389\n",
      "Epoch 952/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1432\n",
      "Epoch 953/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1448\n",
      "Epoch 954/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1384\n",
      "Epoch 955/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1418\n",
      "Epoch 956/1000\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 11.1364\n",
      "Epoch 957/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1423\n",
      "Epoch 958/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1427\n",
      "Epoch 959/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1437\n",
      "Epoch 960/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1431\n",
      "Epoch 961/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1438\n",
      "Epoch 962/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1375\n",
      "Epoch 963/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1419\n",
      "Epoch 964/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1402\n",
      "Epoch 965/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1402\n",
      "Epoch 966/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1491\n",
      "Epoch 967/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1413\n",
      "Epoch 968/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1384\n",
      "Epoch 969/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1406\n",
      "Epoch 970/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1403\n",
      "Epoch 971/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1428\n",
      "Epoch 972/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1385\n",
      "Epoch 973/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1394\n",
      "Epoch 974/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1387\n",
      "Epoch 975/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1371\n",
      "Epoch 976/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1415\n",
      "Epoch 977/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1370\n",
      "Epoch 978/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1406\n",
      "Epoch 979/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1390\n",
      "Epoch 980/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1364\n",
      "Epoch 981/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1392\n",
      "Epoch 982/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1355\n",
      "Epoch 983/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1378\n",
      "Epoch 984/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1342\n",
      "Epoch 985/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1395\n",
      "Epoch 986/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1365\n",
      "Epoch 987/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1402\n",
      "Epoch 988/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1390\n",
      "Epoch 989/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1385\n",
      "Epoch 990/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1369\n",
      "Epoch 991/1000\n",
      "10000/10000 [==============================] - 0s 17us/sample - loss: 11.1357\n",
      "Epoch 992/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1374\n",
      "Epoch 993/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1415\n",
      "Epoch 994/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1387\n",
      "Epoch 995/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1347\n",
      "Epoch 996/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1398\n",
      "Epoch 997/1000\n",
      "10000/10000 [==============================] - 0s 14us/sample - loss: 11.1343\n",
      "Epoch 998/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1354\n",
      "Epoch 999/1000\n",
      "10000/10000 [==============================] - 0s 16us/sample - loss: 11.1389\n",
      "Epoch 1000/1000\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 11.1358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x182c2c2a788>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X, y = Y, epochs = 1000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.128087"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(negloglik(Y, model(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = model.loss_functions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=41183, shape=(), dtype=float32, numpy=6.023795>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.call(Y, model(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense.kernel_regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl.Dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense.a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'sequential/dense/kernel:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[-0.03124883,  0.28588724],\n",
       "        [-0.03150563,  0.2923285 ],\n",
       "        [-0.03221646,  0.28648335]], dtype=float32)>,\n",
       " <tf.Variable 'sequential/dense/bias:0' shape=(2,) dtype=float32, numpy=array([-2.0391998, 16.384024 ], dtype=float32)>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=399687, shape=(100000,), dtype=float32, numpy=\n",
       "array([0.05909398, 0.05949057, 0.06059545, ..., 0.06368538, 0.05943586,\n",
       "       0.06014879], dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X).total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=399747, shape=(100000,), dtype=float32, numpy=\n",
       "array([0.99999475, 0.9999949 , 0.99999505, ..., 0.9999956 , 0.9999945 ,\n",
       "       0.9999949 ], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X).probs_parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss():\n",
    "    return tf.reduce_mean(negloglik(Y, model(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=160078, shape=(), dtype=float32, numpy=11.128087>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = get_loss()\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11.128087, shape=(), dtype=float32)\n",
      "tf.Tensor(11.062134, shape=(), dtype=float32)\n",
      "tf.Tensor(11.052348, shape=(), dtype=float32)\n",
      "tf.Tensor(11.0327, shape=(), dtype=float32)\n",
      "tf.Tensor(10.954716, shape=(), dtype=float32)\n",
      "tf.Tensor(10.967147, shape=(), dtype=float32)\n",
      "tf.Tensor(10.987995, shape=(), dtype=float32)\n",
      "tf.Tensor(10.989368, shape=(), dtype=float32)\n",
      "tf.Tensor(10.980344, shape=(), dtype=float32)\n",
      "tf.Tensor(10.9544935, shape=(), dtype=float32)\n",
      "tf.Tensor(10.939382, shape=(), dtype=float32)\n",
      "tf.Tensor(10.905773, shape=(), dtype=float32)\n",
      "tf.Tensor(10.9035, shape=(), dtype=float32)\n",
      "tf.Tensor(10.890143, shape=(), dtype=float32)\n",
      "tf.Tensor(10.87322, shape=(), dtype=float32)\n",
      "tf.Tensor(10.866693, shape=(), dtype=float32)\n",
      "tf.Tensor(10.856206, shape=(), dtype=float32)\n",
      "tf.Tensor(10.852836, shape=(), dtype=float32)\n",
      "tf.Tensor(10.847836, shape=(), dtype=float32)\n",
      "tf.Tensor(10.839115, shape=(), dtype=float32)\n",
      "tf.Tensor(10.839273, shape=(), dtype=float32)\n",
      "tf.Tensor(10.837333, shape=(), dtype=float32)\n",
      "tf.Tensor(10.829423, shape=(), dtype=float32)\n",
      "tf.Tensor(10.822459, shape=(), dtype=float32)\n",
      "tf.Tensor(10.81615, shape=(), dtype=float32)\n",
      "tf.Tensor(10.803158, shape=(), dtype=float32)\n",
      "tf.Tensor(10.799815, shape=(), dtype=float32)\n",
      "tf.Tensor(10.792518, shape=(), dtype=float32)\n",
      "tf.Tensor(10.787049, shape=(), dtype=float32)\n",
      "tf.Tensor(10.779145, shape=(), dtype=float32)\n",
      "tf.Tensor(10.767272, shape=(), dtype=float32)\n",
      "tf.Tensor(10.762867, shape=(), dtype=float32)\n",
      "tf.Tensor(10.74651, shape=(), dtype=float32)\n",
      "tf.Tensor(10.73223, shape=(), dtype=float32)\n",
      "tf.Tensor(10.728522, shape=(), dtype=float32)\n",
      "tf.Tensor(10.723259, shape=(), dtype=float32)\n",
      "tf.Tensor(10.714698, shape=(), dtype=float32)\n",
      "tf.Tensor(10.704234, shape=(), dtype=float32)\n",
      "tf.Tensor(10.698345, shape=(), dtype=float32)\n",
      "tf.Tensor(10.6850605, shape=(), dtype=float32)\n",
      "tf.Tensor(10.674586, shape=(), dtype=float32)\n",
      "tf.Tensor(10.662194, shape=(), dtype=float32)\n",
      "tf.Tensor(10.654878, shape=(), dtype=float32)\n",
      "tf.Tensor(10.642056, shape=(), dtype=float32)\n",
      "tf.Tensor(10.631108, shape=(), dtype=float32)\n",
      "tf.Tensor(10.605351, shape=(), dtype=float32)\n",
      "tf.Tensor(10.581835, shape=(), dtype=float32)\n",
      "tf.Tensor(10.576468, shape=(), dtype=float32)\n",
      "tf.Tensor(10.56777, shape=(), dtype=float32)\n",
      "tf.Tensor(10.547681, shape=(), dtype=float32)\n",
      "tf.Tensor(10.535858, shape=(), dtype=float32)\n",
      "tf.Tensor(10.533283, shape=(), dtype=float32)\n",
      "tf.Tensor(10.528673, shape=(), dtype=float32)\n",
      "tf.Tensor(10.517235, shape=(), dtype=float32)\n",
      "tf.Tensor(10.505771, shape=(), dtype=float32)\n",
      "tf.Tensor(10.496074, shape=(), dtype=float32)\n",
      "tf.Tensor(10.482563, shape=(), dtype=float32)\n",
      "tf.Tensor(10.474223, shape=(), dtype=float32)\n",
      "tf.Tensor(10.455769, shape=(), dtype=float32)\n",
      "tf.Tensor(10.434561, shape=(), dtype=float32)\n",
      "tf.Tensor(10.43303, shape=(), dtype=float32)\n",
      "tf.Tensor(10.421396, shape=(), dtype=float32)\n",
      "tf.Tensor(10.407919, shape=(), dtype=float32)\n",
      "tf.Tensor(10.404422, shape=(), dtype=float32)\n",
      "tf.Tensor(10.377621, shape=(), dtype=float32)\n",
      "tf.Tensor(10.362243, shape=(), dtype=float32)\n",
      "tf.Tensor(10.352193, shape=(), dtype=float32)\n",
      "tf.Tensor(10.335255, shape=(), dtype=float32)\n",
      "tf.Tensor(10.313677, shape=(), dtype=float32)\n",
      "tf.Tensor(10.293822, shape=(), dtype=float32)\n",
      "tf.Tensor(10.291778, shape=(), dtype=float32)\n",
      "tf.Tensor(10.278628, shape=(), dtype=float32)\n",
      "tf.Tensor(10.278681, shape=(), dtype=float32)\n",
      "tf.Tensor(10.2578335, shape=(), dtype=float32)\n",
      "tf.Tensor(10.249442, shape=(), dtype=float32)\n",
      "tf.Tensor(10.240421, shape=(), dtype=float32)\n",
      "tf.Tensor(10.222269, shape=(), dtype=float32)\n",
      "tf.Tensor(10.206071, shape=(), dtype=float32)\n",
      "tf.Tensor(10.197333, shape=(), dtype=float32)\n",
      "tf.Tensor(10.204424, shape=(), dtype=float32)\n",
      "tf.Tensor(10.195198, shape=(), dtype=float32)\n",
      "tf.Tensor(10.188385, shape=(), dtype=float32)\n",
      "tf.Tensor(10.179186, shape=(), dtype=float32)\n",
      "tf.Tensor(10.150958, shape=(), dtype=float32)\n",
      "tf.Tensor(10.137685, shape=(), dtype=float32)\n",
      "tf.Tensor(10.122997, shape=(), dtype=float32)\n",
      "tf.Tensor(10.115479, shape=(), dtype=float32)\n",
      "tf.Tensor(10.105948, shape=(), dtype=float32)\n",
      "tf.Tensor(10.101567, shape=(), dtype=float32)\n",
      "tf.Tensor(10.100146, shape=(), dtype=float32)\n",
      "tf.Tensor(10.074042, shape=(), dtype=float32)\n",
      "tf.Tensor(10.073269, shape=(), dtype=float32)\n",
      "tf.Tensor(10.044599, shape=(), dtype=float32)\n",
      "tf.Tensor(10.035975, shape=(), dtype=float32)\n",
      "tf.Tensor(10.00765, shape=(), dtype=float32)\n",
      "tf.Tensor(9.995514, shape=(), dtype=float32)\n",
      "tf.Tensor(9.9790125, shape=(), dtype=float32)\n",
      "tf.Tensor(9.983617, shape=(), dtype=float32)\n",
      "tf.Tensor(9.966846, shape=(), dtype=float32)\n",
      "tf.Tensor(9.902254, shape=(), dtype=float32)\n",
      "tf.Tensor(9.865993, shape=(), dtype=float32)\n",
      "tf.Tensor(9.828044, shape=(), dtype=float32)\n",
      "tf.Tensor(9.816119, shape=(), dtype=float32)\n",
      "tf.Tensor(9.748923, shape=(), dtype=float32)\n",
      "tf.Tensor(9.692522, shape=(), dtype=float32)\n",
      "tf.Tensor(9.680679, shape=(), dtype=float32)\n",
      "tf.Tensor(9.633367, shape=(), dtype=float32)\n",
      "tf.Tensor(9.6013155, shape=(), dtype=float32)\n",
      "tf.Tensor(9.581225, shape=(), dtype=float32)\n",
      "tf.Tensor(9.551702, shape=(), dtype=float32)\n",
      "tf.Tensor(9.475057, shape=(), dtype=float32)\n",
      "tf.Tensor(9.467301, shape=(), dtype=float32)\n",
      "tf.Tensor(9.452531, shape=(), dtype=float32)\n",
      "tf.Tensor(9.453978, shape=(), dtype=float32)\n",
      "tf.Tensor(9.42744, shape=(), dtype=float32)\n",
      "tf.Tensor(9.431638, shape=(), dtype=float32)\n",
      "tf.Tensor(9.407669, shape=(), dtype=float32)\n",
      "tf.Tensor(9.39458, shape=(), dtype=float32)\n",
      "tf.Tensor(9.377785, shape=(), dtype=float32)\n",
      "tf.Tensor(9.358365, shape=(), dtype=float32)\n",
      "tf.Tensor(9.3329315, shape=(), dtype=float32)\n",
      "tf.Tensor(9.312762, shape=(), dtype=float32)\n",
      "tf.Tensor(9.315154, shape=(), dtype=float32)\n",
      "tf.Tensor(9.318191, shape=(), dtype=float32)\n",
      "tf.Tensor(9.301692, shape=(), dtype=float32)\n",
      "tf.Tensor(9.285746, shape=(), dtype=float32)\n",
      "tf.Tensor(9.292421, shape=(), dtype=float32)\n",
      "tf.Tensor(9.287965, shape=(), dtype=float32)\n",
      "tf.Tensor(9.199787, shape=(), dtype=float32)\n",
      "tf.Tensor(9.183827, shape=(), dtype=float32)\n",
      "tf.Tensor(9.08603, shape=(), dtype=float32)\n",
      "tf.Tensor(9.049033, shape=(), dtype=float32)\n",
      "tf.Tensor(8.879545, shape=(), dtype=float32)\n",
      "tf.Tensor(8.833886, shape=(), dtype=float32)\n",
      "tf.Tensor(8.81579, shape=(), dtype=float32)\n",
      "tf.Tensor(8.797817, shape=(), dtype=float32)\n",
      "tf.Tensor(8.788895, shape=(), dtype=float32)\n",
      "tf.Tensor(8.762327, shape=(), dtype=float32)\n",
      "tf.Tensor(8.782189, shape=(), dtype=float32)\n",
      "tf.Tensor(8.765234, shape=(), dtype=float32)\n",
      "tf.Tensor(8.715898, shape=(), dtype=float32)\n",
      "tf.Tensor(8.723333, shape=(), dtype=float32)\n",
      "tf.Tensor(8.750722, shape=(), dtype=float32)\n",
      "tf.Tensor(8.779066, shape=(), dtype=float32)\n",
      "tf.Tensor(8.738425, shape=(), dtype=float32)\n",
      "tf.Tensor(8.680108, shape=(), dtype=float32)\n",
      "tf.Tensor(8.64838, shape=(), dtype=float32)\n",
      "tf.Tensor(8.667663, shape=(), dtype=float32)\n",
      "tf.Tensor(8.53324, shape=(), dtype=float32)\n",
      "tf.Tensor(8.56102, shape=(), dtype=float32)\n",
      "tf.Tensor(8.524619, shape=(), dtype=float32)\n",
      "tf.Tensor(8.55237, shape=(), dtype=float32)\n",
      "tf.Tensor(8.586346, shape=(), dtype=float32)\n",
      "tf.Tensor(8.519171, shape=(), dtype=float32)\n",
      "tf.Tensor(8.4242, shape=(), dtype=float32)\n",
      "tf.Tensor(8.464361, shape=(), dtype=float32)\n",
      "tf.Tensor(8.485083, shape=(), dtype=float32)\n",
      "tf.Tensor(8.456579, shape=(), dtype=float32)\n",
      "tf.Tensor(8.500604, shape=(), dtype=float32)\n",
      "tf.Tensor(8.506964, shape=(), dtype=float32)\n",
      "tf.Tensor(8.529904, shape=(), dtype=float32)\n",
      "tf.Tensor(8.536543, shape=(), dtype=float32)\n",
      "tf.Tensor(8.576429, shape=(), dtype=float32)\n",
      "tf.Tensor(8.571512, shape=(), dtype=float32)\n",
      "tf.Tensor(8.57155, shape=(), dtype=float32)\n",
      "tf.Tensor(8.549679, shape=(), dtype=float32)\n",
      "tf.Tensor(8.552761, shape=(), dtype=float32)\n",
      "tf.Tensor(8.565153, shape=(), dtype=float32)\n",
      "tf.Tensor(8.575267, shape=(), dtype=float32)\n",
      "tf.Tensor(8.575375, shape=(), dtype=float32)\n",
      "tf.Tensor(8.583455, shape=(), dtype=float32)\n",
      "tf.Tensor(8.567173, shape=(), dtype=float32)\n",
      "tf.Tensor(8.566441, shape=(), dtype=float32)\n",
      "tf.Tensor(8.581869, shape=(), dtype=float32)\n",
      "tf.Tensor(8.5717325, shape=(), dtype=float32)\n",
      "tf.Tensor(8.578822, shape=(), dtype=float32)\n",
      "tf.Tensor(8.579406, shape=(), dtype=float32)\n",
      "tf.Tensor(8.588714, shape=(), dtype=float32)\n",
      "tf.Tensor(8.584358, shape=(), dtype=float32)\n",
      "tf.Tensor(8.571071, shape=(), dtype=float32)\n",
      "tf.Tensor(8.55764, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.560568, shape=(), dtype=float32)\n",
      "tf.Tensor(8.544261, shape=(), dtype=float32)\n",
      "tf.Tensor(8.556552, shape=(), dtype=float32)\n",
      "tf.Tensor(8.558686, shape=(), dtype=float32)\n",
      "tf.Tensor(8.553261, shape=(), dtype=float32)\n",
      "tf.Tensor(8.571409, shape=(), dtype=float32)\n",
      "tf.Tensor(8.556756, shape=(), dtype=float32)\n",
      "tf.Tensor(8.569316, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570954, shape=(), dtype=float32)\n",
      "tf.Tensor(8.575504, shape=(), dtype=float32)\n",
      "tf.Tensor(8.5664015, shape=(), dtype=float32)\n",
      "tf.Tensor(8.569334, shape=(), dtype=float32)\n",
      "tf.Tensor(8.566512, shape=(), dtype=float32)\n",
      "tf.Tensor(8.562978, shape=(), dtype=float32)\n",
      "tf.Tensor(8.55217, shape=(), dtype=float32)\n",
      "tf.Tensor(8.542455, shape=(), dtype=float32)\n",
      "tf.Tensor(8.541173, shape=(), dtype=float32)\n",
      "tf.Tensor(8.535672, shape=(), dtype=float32)\n",
      "tf.Tensor(8.543259, shape=(), dtype=float32)\n",
      "tf.Tensor(8.563656, shape=(), dtype=float32)\n",
      "tf.Tensor(8.556761, shape=(), dtype=float32)\n",
      "tf.Tensor(8.573159, shape=(), dtype=float32)\n",
      "tf.Tensor(8.560106, shape=(), dtype=float32)\n",
      "tf.Tensor(8.540942, shape=(), dtype=float32)\n",
      "tf.Tensor(8.560428, shape=(), dtype=float32)\n",
      "tf.Tensor(8.557545, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570647, shape=(), dtype=float32)\n",
      "tf.Tensor(8.571525, shape=(), dtype=float32)\n",
      "tf.Tensor(8.56354, shape=(), dtype=float32)\n",
      "tf.Tensor(8.5718, shape=(), dtype=float32)\n",
      "tf.Tensor(8.584282, shape=(), dtype=float32)\n",
      "tf.Tensor(8.564216, shape=(), dtype=float32)\n",
      "tf.Tensor(8.572613, shape=(), dtype=float32)\n",
      "tf.Tensor(8.572618, shape=(), dtype=float32)\n",
      "tf.Tensor(8.56028, shape=(), dtype=float32)\n",
      "tf.Tensor(8.542595, shape=(), dtype=float32)\n",
      "tf.Tensor(8.557101, shape=(), dtype=float32)\n",
      "tf.Tensor(8.574717, shape=(), dtype=float32)\n",
      "tf.Tensor(8.574642, shape=(), dtype=float32)\n",
      "tf.Tensor(8.561477, shape=(), dtype=float32)\n",
      "tf.Tensor(8.569481, shape=(), dtype=float32)\n",
      "tf.Tensor(8.57394, shape=(), dtype=float32)\n",
      "tf.Tensor(8.573557, shape=(), dtype=float32)\n",
      "tf.Tensor(8.567554, shape=(), dtype=float32)\n",
      "tf.Tensor(8.562957, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570396, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570669, shape=(), dtype=float32)\n",
      "tf.Tensor(8.567817, shape=(), dtype=float32)\n",
      "tf.Tensor(8.574562, shape=(), dtype=float32)\n",
      "tf.Tensor(8.557025, shape=(), dtype=float32)\n",
      "tf.Tensor(8.541437, shape=(), dtype=float32)\n",
      "tf.Tensor(8.563802, shape=(), dtype=float32)\n",
      "tf.Tensor(8.573768, shape=(), dtype=float32)\n",
      "tf.Tensor(8.572386, shape=(), dtype=float32)\n",
      "tf.Tensor(8.575393, shape=(), dtype=float32)\n",
      "tf.Tensor(8.5386095, shape=(), dtype=float32)\n",
      "tf.Tensor(8.549979, shape=(), dtype=float32)\n",
      "tf.Tensor(8.573264, shape=(), dtype=float32)\n",
      "tf.Tensor(8.577111, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570481, shape=(), dtype=float32)\n",
      "tf.Tensor(8.593414, shape=(), dtype=float32)\n",
      "tf.Tensor(8.56108, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570148, shape=(), dtype=float32)\n",
      "tf.Tensor(8.573452, shape=(), dtype=float32)\n",
      "tf.Tensor(8.574275, shape=(), dtype=float32)\n",
      "tf.Tensor(8.5563965, shape=(), dtype=float32)\n",
      "tf.Tensor(8.55601, shape=(), dtype=float32)\n",
      "tf.Tensor(8.556784, shape=(), dtype=float32)\n",
      "tf.Tensor(8.573679, shape=(), dtype=float32)\n",
      "tf.Tensor(8.562097, shape=(), dtype=float32)\n",
      "tf.Tensor(8.547164, shape=(), dtype=float32)\n",
      "tf.Tensor(8.538679, shape=(), dtype=float32)\n",
      "tf.Tensor(8.569261, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570043, shape=(), dtype=float32)\n",
      "tf.Tensor(8.568287, shape=(), dtype=float32)\n",
      "tf.Tensor(8.558022, shape=(), dtype=float32)\n",
      "tf.Tensor(8.557965, shape=(), dtype=float32)\n",
      "tf.Tensor(8.55748, shape=(), dtype=float32)\n",
      "tf.Tensor(8.572562, shape=(), dtype=float32)\n",
      "tf.Tensor(8.565881, shape=(), dtype=float32)\n",
      "tf.Tensor(8.561098, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570113, shape=(), dtype=float32)\n",
      "tf.Tensor(8.574709, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570941, shape=(), dtype=float32)\n",
      "tf.Tensor(8.582031, shape=(), dtype=float32)\n",
      "tf.Tensor(8.574531, shape=(), dtype=float32)\n",
      "tf.Tensor(8.571545, shape=(), dtype=float32)\n",
      "tf.Tensor(8.545185, shape=(), dtype=float32)\n",
      "tf.Tensor(8.569532, shape=(), dtype=float32)\n",
      "tf.Tensor(8.560458, shape=(), dtype=float32)\n",
      "tf.Tensor(8.56137, shape=(), dtype=float32)\n",
      "tf.Tensor(8.571117, shape=(), dtype=float32)\n",
      "tf.Tensor(8.572964, shape=(), dtype=float32)\n",
      "tf.Tensor(8.574354, shape=(), dtype=float32)\n",
      "tf.Tensor(8.574944, shape=(), dtype=float32)\n",
      "tf.Tensor(8.56095, shape=(), dtype=float32)\n",
      "tf.Tensor(8.571167, shape=(), dtype=float32)\n",
      "tf.Tensor(8.5724325, shape=(), dtype=float32)\n",
      "tf.Tensor(8.556764, shape=(), dtype=float32)\n",
      "tf.Tensor(8.538649, shape=(), dtype=float32)\n",
      "tf.Tensor(8.542572, shape=(), dtype=float32)\n",
      "tf.Tensor(8.546622, shape=(), dtype=float32)\n",
      "tf.Tensor(8.575432, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570147, shape=(), dtype=float32)\n",
      "tf.Tensor(8.5733595, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570241, shape=(), dtype=float32)\n",
      "tf.Tensor(8.572857, shape=(), dtype=float32)\n",
      "tf.Tensor(8.574482, shape=(), dtype=float32)\n",
      "tf.Tensor(8.547066, shape=(), dtype=float32)\n",
      "tf.Tensor(8.569965, shape=(), dtype=float32)\n",
      "tf.Tensor(8.57276, shape=(), dtype=float32)\n",
      "tf.Tensor(8.573206, shape=(), dtype=float32)\n",
      "tf.Tensor(8.572385, shape=(), dtype=float32)\n",
      "tf.Tensor(8.563092, shape=(), dtype=float32)\n",
      "tf.Tensor(8.567048, shape=(), dtype=float32)\n",
      "tf.Tensor(8.569136, shape=(), dtype=float32)\n",
      "tf.Tensor(8.543573, shape=(), dtype=float32)\n",
      "tf.Tensor(8.543433, shape=(), dtype=float32)\n",
      "tf.Tensor(8.539846, shape=(), dtype=float32)\n",
      "tf.Tensor(8.568919, shape=(), dtype=float32)\n",
      "tf.Tensor(8.560839, shape=(), dtype=float32)\n",
      "tf.Tensor(8.557249, shape=(), dtype=float32)\n",
      "tf.Tensor(8.568771, shape=(), dtype=float32)\n",
      "tf.Tensor(8.553467, shape=(), dtype=float32)\n",
      "tf.Tensor(8.574659, shape=(), dtype=float32)\n",
      "tf.Tensor(8.567189, shape=(), dtype=float32)\n",
      "tf.Tensor(8.575239, shape=(), dtype=float32)\n",
      "tf.Tensor(8.570873, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-4913b29af499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python_projects\\workon_hrab2\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python_projects\\workon_hrab2\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python_projects\\workon_hrab2\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python_projects\\workon_hrab2\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python_projects\\workon_hrab2\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python_projects\\workon_hrab2\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\python_projects\\workon_hrab2\\WPy64-3740\\python-3.7.4.amd64\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    loss = train_step()\n",
    "    if i % 100 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'sequential/dense/kernel:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[0.9516669, 3.0018325],\n",
       "        [1.9121954, 2.0007813],\n",
       "        [2.794243 , 1.00997  ]], dtype=float32)>,\n",
       " <tf.Variable 'sequential/dense/bias:0' shape=(2,) dtype=float32, numpy=array([2.942339  , 0.03384899], dtype=float32)>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
